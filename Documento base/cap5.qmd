---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r include=FALSE, warning=FALSE}
library(readr)
library(readxl)
library(janitor)
library(mice)
library(visdat)
library(outliers)
library(plotly)
library(tidyverse)
library(webshot2)
library(lmtest)      
library(tseries)     
library(ggfortify)   

```

# Construcción del modelo

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(
  fig.width = 6, 
  fig.height = 4, 
  dev = "png",
  fig.align = "center"
)
theme_set(theme_minimal(base_size = 12))
```

En este capítulo desarrollaremos el procedimiento de construcción de diferentes modelos estadísticos con el objetivo de explicar y predecir la percepción de felicidad (Happiness Score) a lo largo del tiempo, utilizando los datos longitudinales de la base de datos explicada en el capítulo anterior.

El propósito del capítulo es construir un modelo que sea estadísticamente sólido y, al mismo tiempo, interpretable desde el punto de vista de los diferentes factores sociales, económicos y políticos que puedan influir a la felicidad. Para ello, combinaremos técnicas de la estadística clásica (regresión lineal múltiple) con modelos diseñados específicamente para datos longitudinales, como los modelos lineales mixtos (LMM) y los modelos lineales generalizados mixtos (GLMM), que permiten capturar adecuadamente la estructura jerárquica de los datos y la dependencia entre medidas repetidas.

El modelado clásico se abordará desde dos estrategias complementarias:

-   **Top-down**: partimos de un modelo completo que incluye todas las variables relevantes, y vamos eliminando aquellas que consideremos que no aportan información significativa o que generan problemas como multicolinealidad o sobreajuste.

-   **Bottom-up**: comenzamos con un modelo simple con pocas variables y vamos añadiendo progresivamente nuevas variables explicativas, evaluando si su incorporación mejora el ajuste del modelo.

Ambas estrategias nos permiten explorar distintos métodos de construcción del modelo y encontrar un equilibrio entre simplicidad, robustez y capacidad explicativa.

En cambio, para los modelos mixtos (LMM y GLMM) seguimos un enfoque orientado a la validación: partimos directamente de estructuras con efectos aleatorios y efectos fijos determinados, evaluando su adecuación con herramientas gráficas y pruebas estadísticas. En el caso del LMM se emplea una estructura con todas las variables como efectos fijos y `year` como efecto aleatorio, mientras que para el GLMM se exploran múltiples combinaciones hasta identificar un modelo válido con distribución Gamma y `regional_indicator` como efecto aleatorio.

Dado que trabajamos con datos que varían a lo largo del tiempo para cada país, es importante distinguir entre:

-   **Variables longitudinales**: cambian con el tiempo (por ejemplo, `gdp`, `support`, `freedom`, `generosity`, `life_exp`, `corruption`).

-   **Variables fijas**: son aquellas que no cambian a lo largo del tiempo dentro del periodo de análisis, o que se consideran características estructurales del país. Como mencionamos anteriormente, estas variables se utilizan como contexto porque aportan información relevante sobre el entorno político o geográfico en el que se sitúa cada observación. Por ejemplo, `region` indica la ubicación geográfica del país y puede influir en aspectos culturales, económicos o sociales; al igual que las variables políticas que hemos incorporado como "foto" desde otras bases de datos como `is_democracy`, `regime_category`, `has_free_and_fair_election` o `has_alternation`.

En cuanto a la organización del capítulo, comenzaremos estudiando la relación entre las distintas variables de nuestra base de datos, revisando lo observado en el capítulo anterior pero con vistas a sacar posibles hipótesis sobre el posible efecto que tendrán en los modelos. Después, describiremos los criterios de selección de variables y la estrategia general de modelado en el caso de la regresión lineal múltiple; seguido del diagnóstico y validación del modelo clásico resultante. Posteriormente, se abordarán los modelos lineales mixtos (LMM) y los modelos lineales generalizados mixtos (GLMM), detallando aquellos que resultaron válidos y se utilizaron para predecir la evolución del Happiness Score. El capítulo concluye con una comparación de los modelos ajustados y una reflexión sobre sus implicaciones prácticas.

## Análisis exploratorio y selección inicial de variables

Aunque ya hemos analizado previamente la estructura de los datos, antes de ajustar los modelos es útil revisar de nuevo las características más relevantes de cara a identificar posibles variables que podrían actuar como buenos predictores del `happiness_score`.

### Estructura del dataset longitudinal

Nuestro conjunto de datos contiene observaciones anuales de múltiples países en el período 2015–2024, y está definido a través de variables socioeconómicas y de diferentes factores políticos. Las variables disponibles, descritas en el capítulo anterior, son: `regional_indicator`, `gdp`, `support`, `life_exp`, `freedom`, `generosity`, `corruption`, `status`, `political_rights`, `civil_liberties`, `fair_election`, `regime_category`, `democracy`, `electoral_category`, `presidential`, `alternation` y `year`.

Dado el planteamiento longitudinal de nuestro estudio, empleamos `country` como unidad de agrupación para modelar efectos aleatorios específicos de cada país a lo largo del tiempo, captando así variaciones propias de la evolución de cada país. Por otro lado, la variable `year` se incluye como efecto fijo porque el tiempo es un elemento compartido por todos los países; aunque su uso como efecto aleatorio se explora en los modelos mixtos más complejos ya que modelando la variabilidad entre años podemos captar diferentes factores que afectan a la felicidad en cada uno de ellos. De la misma manera, la variable `regional_indicator` también se incluye como efecto aleatorio ya que modelando la variabilidad entre regiones podemos tener en cuenta las diferentes dependencias estructurales entre países que pertenecen a la misma región. 

### Visualización y evolución temporal de las variables

Antes de proceder al ajuste del modelo, vamos a recordar cómo evolucionan algunas de las principales variables explicativas a lo largo del tiempo. En la @fig-evolucion-variables se muestran los gráficos de evolución de tres de las variables más relevantes: `happiness_score`, `corruption` y `generosity`. Hemos seleccionado estas dos últimas variables ya que consideramos que pueden tener cierta influencia en la evolución de la felicidad a lo largo del tiempo.

Esta visualización nos permite identificar posibles tendencias globales a lo largo del tiempo, lo cual resulta clave para elegir la estructura con la que construiremos nuestros modelos más adelante.

```{r}
#| label: fig-evolucion-variables
#| echo: false
#| warning: false
#| fig-cap: "Evolución de la media anual de las variables felicidad, generosidad y percepción de corrupción (2015-2024)."
#| fig-width: 5
#| fig-height: 3.5
library(ggplot2)
library(dplyr)
library(patchwork)
df_sin_democracia_sin_na <- read.csv("df_sin_democracia_sin_na.csv")
df_sin_democracia_sin_na <- read.csv("df_sin_democracia_sin_na.csv")
# Dataset filtrado
df_temp <- df_sin_democracia_sin_na %>%
  filter(year %in% 2015:2024) %>%
  group_by(year) %>%
  summarise(
    felicidad = mean(happiness_score, na.rm = TRUE),
    generosidad = mean(generosity, na.rm = TRUE),
    corrupcion = mean(corruption, na.rm = TRUE)
  )

# Gráfico 1: Felicidad
g1 <- ggplot(df_temp, aes(x = factor(year), y = felicidad)) +
  geom_line(color = "#1b9e77", size = 1.2) +
  geom_point(color = "#1b9e77", size = 2) +
  labs(y = "Felicidad", x = NULL) +
  theme_minimal()  

# Gráfico 2: Generosidad
g2 <- ggplot(df_temp, aes(x = factor(year), y = generosidad)) +
  geom_line(color = "#d95f02", size = 1.2) +
  geom_point(color = "#d95f02", size = 2) +
  labs(y = "Generosidad", x = NULL) +
  theme_minimal()  

# Gráfico 3: Corrupción
g3 <- ggplot(df_temp, aes(x = factor(year), y = corrupcion)) +
  geom_line(color = "#7570b3", size = 1.2) +
  geom_point(color = "#7570b3", size = 2) +
  labs(y = "Corrupción", x = "Año") +
  theme_minimal()  

(g1 / g2 / g3) +
  plot_annotation(title = "Evolución temporal de variables clave (2015-2024)")
```

```{r warning=FALSE, include=FALSE}
# Carga de paquetes 
library(readr)
library(readxl)
library(janitor)
library(mice)
library(visdat)
library(outliers)
library(plotly)
library(tidyverse)
library(webshot2)

# Cargamos los datos 
df_original <- read_delim("world_happiness_combined.csv", delim = ";", show_col_types = FALSE)
# Limpiar nombres de columnas
df_original <- clean_names(df_original)
summary(df_original)
str(df_original)
# Hay algunas variables numérias que están puestas como categóricas
df_original <- df_original %>%
  mutate(
    gdp_per_capita = as.numeric(gsub(",", ".", gdp_per_capita)),
    social_support = as.numeric(gsub(",", ".", social_support)),
    freedom_to_make_life_choices = as.numeric(gsub(",", ".", freedom_to_make_life_choices)),
    generosity = as.numeric(gsub(",", ".", generosity)),
    perceptions_of_corruption = as.numeric(gsub(",", ".", perceptions_of_corruption))
  )
# Verificar que ahora sean numéricas
str(df_original)
# Hay un problema con las comas en el happiness score
df_original$happiness_score <- df_original$happiness_score / 100000
# Datos faltantes
is.na(df_original)
# En la base de datos no hay ningún dato faltante

# Detección de Outliers
boxplot(df_original$happiness_score)
boxplot(df_original$gdp_per_capita)
boxplot(df_original$social_support)  
boxplot(df_original$healthy_life_expectancy)
boxplot(df_original$freedom_to_make_life_choices)
boxplot(df_original$generosity)
boxplot(df_original$perceptions_of_corruption)
# Como podemos apreciar gráficamente, hay algunas variables numéricas en las que puede haber valores atípicos
outliers::grubbs.test(df_original$happiness_score)
outliers::grubbs.test(df_original$gdp_per_capita)
outliers::grubbs.test(df_original$social_support)
outliers::grubbs.test(df_original$healthy_life_expectancy)
outliers::grubbs.test(df_original$freedom_to_make_life_choices)
outliers::grubbs.test(df_original$generosity)
outliers::grubbs.test(df_original$perceptions_of_corruption)
# Como el p-valor es > alpha en todos los test, no tenemos outliers
df_original <- df_original %>%
  rename(
    gdp = gdp_per_capita,
    support = social_support,
    life_exp = healthy_life_expectancy,
    freedom = freedom_to_make_life_choices,
    generosity = generosity,
    corruption = perceptions_of_corruption
  )
```

```{r include=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(stringr)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(htmlwidgets)
## FREEDOM IN THE WORLD
freedom_todos <- read_excel("All_data_FIW_2013-2024 (1).xlsx", sheet = "FIW13-25", skip = 1)
### Las variables que nos pueden llegar a interesar son:
#### Country/Territory (necesitamos el país/territorio)
#### Region (aunque sea muy parecida a la de regional_indicator, nos puede ser de utilidad)
#### c/T (indica si es país o territorio, aunque no se si deberíamos de meternos con el concepto de soberanía)
#### Edition (necesitamos el año)
#### Status (clasifica la libertad del país)
#### PR (derechos políticos) rating y CL (libertades civiles) rating (la otra opción sería elegir PR, CL y Total porque el rating va de 1 a 7)
freedom_final <- freedom_todos %>%
  select(
    `Country/Territory`, # Nombre del país o territorio
    `Region`,            # Región geográfica
    `C/T`,               # Indica si es país (c) o territorio (t)
    `Edition`,           # Año de edición de los datos
    `Status`,            # Clasificación de libertad (Libre, Parcialmente Libre, No Libre)
    `PR rating`,         # Puntuación de derechos políticos (1-7)
    `CL rating`          # Puntuación de libertades civiles (1-7)
  ) %>%
  rename(
    country = `Country/Territory`,
    region = `Region`,
    country_or_territory = `C/T`,
    year = `Edition`,
    status = `Status`,
    political_rights = `PR rating`,
    civil_liberties = `CL rating`
  )
freedom_final <- freedom_final %>%
  filter(year >= 2015 & year <= 2024)
## DEMOCRACY DATA ==> DEMOCRACY AND DICTATORSHIP
library(democracyData)
democracy_data <-
  democracyData::pacl_update |> 
  janitor::clean_names() |> 
  dplyr::select(
    "country_name" = "pacl_update_country",
    "country_code" = "pacl_update_country_isocode",
    "year",
    "regime_category_index" = "dd_regime",
    "regime_category" = "dd_category",
    "is_monarchy" = "monarchy",
    "is_commonwealth" = "commonwealth",
    "monarch_name",
    "monarch_accession_year" = "monarch_accession",
    "monarch_birthyear",
    "is_female_monarch" = "female_monarch",
    "is_democracy" = "democracy",
    "is_presidential" = "presidential",
    "president_name",
    "president_accesion_year" = "president_accesion",
    "president_birthyear",
    "is_interim_phase" = "interim_phase",
    "is_female_president" = "female_president",
    "is_colony" = "colony",
    "colony_of",
    "colony_administrated_by",
    "is_communist" = "communist",
    "has_regime_change_lag" = "regime_change_lag",
    "spatial_democracy",
    "parliament_chambers" = "no_of_chambers_in_parliament",
    "has_proportional_voting" = "proportional_voting",
    "election_system",
    "lower_house_members" = "no_of_members_in_lower_house",
    "upper_house_members" = "no_of_members_in_upper_house",
    "third_house_members" = "no_of_members_in_third_house",
    "has_new_constitution" = "new_constitution",
    "has_full_suffrage" = "fullsuffrage",
    "suffrage_restriction",
    "electoral_category_index" = "electoral",
    "spatial_electoral",
    "has_alternation" = "alternation",
    "is_multiparty" = "multiparty",
    "has_free_and_fair_election" = "free_and_fair_election",
    "parliamentary_election_year",
    "election_month" = "election_month_year",
    "has_postponed_election" = "postponed_election"
  ) |>
  dplyr::mutate(
    election_month = dplyr::na_if(.data$election_month, "?")
  ) |> 
  tidyr::separate_wider_regex(
    "election_month",
    patterns = c(
      election_month = "\\D+",
      election_year = "\\d{4}$"
    ),
    too_few = "align_start"
  ) |> 
  dplyr::mutate(
    electoral_category = dplyr::case_match(
      .data$electoral_category_index,
      0 ~ "no elections",
      1 ~ "single-party elections",
      2 ~ "non-democratic multi-party elections",
      3 ~ "democratic elections"
    ),
    .after = "electoral_category_index"
  ) |> 
  dplyr::mutate(
    election_month = stringr::str_squish(.data$election_month),
    dplyr::across(
      c(
        tidyselect::ends_with("_index"),
        tidyselect::contains("year"),
        tidyselect::ends_with("_members"),
        "parliament_chambers"
      ),
      as.integer
    ),
    dplyr::across(
      c(
        tidyselect::starts_with("is_"),
        tidyselect::starts_with("has_")
      ),
      as.logical
    )
  )
### Las variables que nos pueden llegar a interesar son:
#### country_name (necesitamos el país/territorio)
#### year (año)
#### regime_category (Parliamentary democracies, Mixed democracies (with weak presidents), Presidential democracies, Civilian autocracies, Military dictatorships, Royal dictatorships)
#### is_monarchy (es monarquía o no)
#### is_democracia (es democracia o no)
#### is_presidential (es presidencial o no)
#### is_colony (es colonia o no)
#### is_communist (es comunista o no)
#### spatial_democracy (como de democráticos son sus países vecinos) 
#### has_full_suffrage (tiene sufragio universal o no)
#### electoral_category (No elections, Single-party elections, non-democratic multi-party elections, democratic elections)
#### spatial_electoral (cómo son las elecciones en sus países vecinos)
#### has_free_and_fair_election (tienen elecciones justas o no)
#### has_alternation (cambian de gobierno o no)
democracy_final <- democracy_data %>%
  select(
    country_name, 
    year, 
    regime_category, 
    is_monarchy, 
    is_democracy, 
    is_presidential, 
    is_colony, 
    is_communist, 
    spatial_democracy, 
    has_full_suffrage, 
    electoral_category, 
    spatial_electoral, 
    has_free_and_fair_election, 
    has_alternation
  ) %>%
  rename(
    monarchy = is_monarchy,
    democracy = is_democracy,
    presidential = is_presidential,
    colony = is_colony,
    communist = is_communist,
    sp_democracy = spatial_democracy,
    suffrage = has_full_suffrage,
    sp_electoral = spatial_electoral,
    fair_election = has_free_and_fair_election,
    alternation = has_alternation
  )
democracy_final <- democracy_final %>%
  filter(year >= 2015 & year <= 2024)
## UNIÓN DE LOS DATASETS
colnames(df_original)
colnames(democracy_final)
colnames(freedom_final)
# Renombrar la columna 'country_name' en democracy_final para que coincida con df_original
democracy_final <- democracy_final %>%
  rename(country = country_name)
# Ver los países en cada dataset para ver si hay alguna diferencia en la nomenclatura
unique(df_original$country)
unique(democracy_final$country)
unique(freedom_final$country)

setdiff(df_original$country, democracy_final$country)
setdiff(democracy_final$country, df_original$country)
setdiff(df_original$country, freedom_final$country)
setdiff(freedom_final$country, df_original$country)
# Corrección de nombres 
df_original <- df_original %>%
  mutate(country = case_when(
    country == "Trinidad & Tobago" ~ "Trinidad and Tobago",
    country == "Somaliland region" ~ "Somaliland",
    country == "Macedonia" ~ "North Macedonia",
    country == "Palestinian Territories" ~ "State of Palestine",
    country == "Congo" ~ "Congo (Kinshasa)",
    country == "Taiwan Province of China" ~ "Taiwan",
    country == "Hong Kong S.A.R. of China" ~ "Hong Kong",
    country == "Czechia" ~ "Czech Republic",
    country == "Turkiye" ~ "Turkey",
    country == "Argelia" ~ "Algeria",
    country == "Eswatini" ~ "Swaziland",
    TRUE ~ country
  ))
democracy_final <- democracy_final %>%
  mutate(country = case_when(
    country == "Slovak Republic" ~ "Slovakia",
    country == "Korea, Republic of" ~ "South Korea",
    country == "Trinidad &Tobago" ~ "Trinidad and Tobago",
    country == "Congo, Dem. Rep." ~ "Congo (Kinshasa)",
    country == "Congo, Republic of" ~ "Congo (Brazzaville)",
    country == "Gambia, The" ~ "Gambia",
    country == "Côte d`Ivoire" ~ "Ivory Coast",
    TRUE ~ country
  ))
freedom_final <- freedom_final %>%
  mutate(country = case_when(
    country == "Northern Cyprus" ~ "North Cyprus",
    country == "The Gambia" ~ "Gambia",
    country == "Cote d'Ivoire" ~ "Ivory Coast",
    country == "Eswatini" ~ "Swaziland",
    TRUE ~ country
  ))

# PRIMER DATAFRAME: df_completo (2015-2020, con todas las variables)
df_completo <- df_original %>%
  left_join(democracy_final, by = c("country", "year")) %>%
  left_join(freedom_final, by = c("country", "year")) %>%
  filter(year >= 2015 & year <= 2020)  # Filtrar solo hasta 2020

# SEGUNDO DATAFRAME: df_sin_democracia (2015-2024, sin democracy_final)
df_sin_democracia <- df_original %>%
  left_join(freedom_final, by = c("country", "year")) %>%
  filter(year >= 2015 & year <= 2024)  # Mantener toda la información de felicidad y libertad

summary(df_completo)
summary(df_sin_democracia)

na_presence_completo <- df_completo %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))

na_presence_sin_democracia <- df_sin_democracia %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))

# OPCIÓN 1: ELIMINAR LOS NA
df_completo_sin_na <- df_completo %>% drop_na()
df_sin_democracia_sin_na <- df_sin_democracia %>% drop_na()

# OPCIÓN 2: SUSTITUIR LOS NA
# VARIABLES NUMÉRICAS
df_completo_numeric <- df_completo %>%
  select_if(is.numeric)
df_sin_democracia_numeric <- df_sin_democracia %>%
  select_if(is.numeric)
imputacion_completo <- mice(df_completo_numeric, method = "pmm", m = 5, maxit = 50, seed = 123)
df_completo_pmm <- complete(imputacion_completo)
imputacion_sin_democracia <- mice(df_sin_democracia_numeric, method = "pmm", m = 5, maxit = 50, seed = 123)
df_sin_democracia_pmm <- complete(imputacion_sin_democracia)
df_completo_pmm <- bind_cols(df_completo %>% select(-colnames(df_completo_numeric)), df_completo_pmm)
df_sin_democracia_pmm <- bind_cols(df_sin_democracia %>% select(-colnames(df_sin_democracia_numeric)), df_sin_democracia_pmm)
# VARIABLES CATEGÓRICAS
md.pattern(df_completo_pmm)
vis_miss(df_completo_pmm, sort_miss=TRUE)
na_presence_completo_pmm <- df_completo_pmm %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))
df_completo_pmm <- df_completo_pmm %>%
  mutate(
    regional_indicator = case_when(
      country == "Greece" ~ "Western Europe",
      country == "Cyprus" ~ "Western Europe",
      country == "Gambia" ~ "Sub-Saharan Africa",
      TRUE ~ regional_indicator
    ),
    colony = ifelse(country == "Libya", FALSE, colony)
  ) %>%
  filter(!country %in% c("North Cyprus", "Kosovo", "Somaliland", "State of Palestine"))


md.pattern(df_sin_democracia_pmm)
vis_miss(df_sin_democracia_pmm, sort_miss=TRUE)
na_presence_sin_democracia_pmm <- df_sin_democracia_pmm %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))
df_sin_democracia_pmm <- df_sin_democracia_pmm %>%
  mutate(
    regional_indicator = case_when(
      country == "Greece" ~ "Western Europe",
      country == "Cyprus" ~ "Western Europe",
      country == "Gambia" ~ "Sub-Saharan Africa",
      TRUE ~ regional_indicator
    ),
  ) %>%
  filter(!country %in% c("State of Palestine"))
# Eliminar territorios
df_sin_democracia_sin_na <- df_sin_democracia_sin_na %>%
  filter(tolower(country_or_territory) == "c") %>%  # Solo países

  # Eliminar la variable 'country_or_territory'
  select(-country_or_territory)
```

Observando la @fig-evolucion-variables, vemos que la generosidad (`generosity`) aumenta moderadamente en los últimos años, mientras que la percepción de corrupción (`corruption`) sufre fluctuaciones abruptas que no nos permiten detectar una tendencia clara. La puntuación de felicidad (`happiness_score`) se mantiene notablemente estable en el tiempo, y, si comparamos su evolución con la de la `generosity`, podemos ver que tienen una evolución bastante similar; por lo que la generosidad puede tener cierto impacto en la evolución de la felicidad. Viendo la evolución de la corrupción, vemos que es necesario utilizar modelos que capten la variabilidad de cada país, ya que el promedio global puede estar ocultando comportamientos diferentes en algunos países.

### Matriz de correlaciones

Antes de ajustar ningún modelo, es útil examinar la correlación entre las variables explicativas numéricas y la variable objetivo `happiness_score`. Esto nos permitirá identificar posibles relaciones lineales, evaluar redundancias y tomar decisiones informadas sobre qué variables incluir inicialmente en el modelo.

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-matriz
#| echo: false
#| warning: false
#| fig-cap: "Matriz de correlaciones de las variables numéricas de nuestra base de datos."
#| fig-width: 5
#| fig-height: 3.5
# Cargar librerías 
library(corrplot)
library(GGally)
library(dplyr)

# Seleccionamos las variables de interés para el modelo
df_modelo <- df_sin_democracia_sin_na %>%
  select(happiness_score, gdp, life_exp, support, freedom, generosity, corruption)

# Calculamos la matriz de correlaciones de Pearson
cor_matrix <- cor(df_modelo, use = "complete.obs", method = "pearson")

# Visualizamos la matriz de correlaciones
corrplot(cor_matrix, method = "color", type = "upper",
         addCoef.col = "black", number.cex = 0.7, tl.cex = 0.8, tl.col = "black",
         col = colorRampPalette(c("red", "white", "blue"))(200))


```

Como observamos en la @fig-matriz, las correlaciones más fuertes con `happiness_score` provienen de:

-   `support` (0.75): el apoyo social es la variable que más se relaciona con la felicidad.

-   `life_exp` (0.67) y gdp (0.63): muestran correlaciones altas, mostrando la importancia del bienestar económico y la salud en la evolución de la felicidad.

-   `freedom` (0.59) también presenta una correlación moderada.

En cambio, variables como `generosity` (0.10) y `corruption` (0.07) muestran una relación muy débil con la felicidad, lo que nos hace cuestionar su importancia explicativa. Las correlaciones entre variables explicativas no son excesivamente altas (ninguna supera 0.8), por lo que, en principio, no deberíamos de tener muchos problemas de multicolinealidad. Aun así, esto se verificará con el cálculo del Variance Inflation Factor (VIF), un indicador que mide cuánto aumenta la varianza de los coeficientes estimados por la multicolinealidad. Un valor de VIF superior a 5 suele considerarse problemático, ya que sugiere una multicolinealidad como mínimo moderada, lo que puede afectar a la estabilidad e interpretación de los coeficientes. En este trabajo utilizamos el VIF para asegurarnos que las variables seleccionadas no tienen demasiada correlación entre ellas.

Si nos guiáramos exclusivamente por la matriz de correlaciones, deberíamos de incluir `support`, `life_exp`, `gdp` y `freedom` en el modelo, pero estas correlaciones deben interpretarse con cautela ya que se calculan sobre medidas repetidas para los mismos países a lo largo del tiempo; lo que puede llevar a una fuerte correlación debido a la estructura longitudinal de los datos.

## Criterios de selección del modelo

Al construir un modelo estadístico, nos encontramos con el caso de que contamos con múltiples combinaciones posibles de variables explicativas. Para elegir la combinación más adecuada, se utilizan criterios que balancean dos aspectos fundamentales: el ajuste al conjunto de datos (lo bien que predice el modelo los datos observados), y la complejidad del modelo (cuántos parámetros se incluyen). Dos de los criterios más utilizados para este propósito son el Akaike Information Criterion (AIC) y el Bayesian Information Criterion (BIC).

AIC penaliza la complejidad del modelo y busca minimizar la pérdida de información. Se calcula como: $$
\text{AIC} = -2 \cdot \log(\hat{L}) + 2k.
$$ donde $\hat{L}$ es la verosimilitud máxima del modelo y $k$ el número de parámetros.

BIC penaliza de manera más severa los modelos complejos (dependiendo del tamaño de muestra $n$): $$
\text{BIC} = -2 \cdot \log(\hat{L}) + k \cdot \log(n).
$$ Un AIC o BIC más bajo indica un mejor modelo, pero el AIC tiende a ser más flexible con modelos más complejos; mientras que el BIC favorece modelos más sencillos. 

## Modelado clásico

Como punto de partida, partiremos de un modelo clásico de regresión lineal múltiple para explicar el `happiness_score` a partir de variables como `gdp`, `life_exp`, `support`, `freedom`, `generosity` y `corruption`. Para explorar la mejor combinación de predictores, aplicamos dos estrategias de selección de variables:

```{r message=FALSE, warning=FALSE, include=FALSE}
# Ajuste del modelo completo
modelo_completo <- lm(happiness_score ~ gdp + life_exp + support + freedom + generosity + corruption, data = df_sin_democracia_sin_na)

summary(modelo_completo)

```

### Estrategia top-down (backward elimination)

Usamos el criterio AIC y BIC para eliminar aquellas variables cuya exclusión mejora la simplicidad del modelo sin sacrificar capacidad predictiva. A continuación, se muestra la salida completa generada por R utilizando los criterios AIC y BIC, respectivamente:

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Selección con AIC
modelo_step_aic <- step(modelo_completo, direction = "backward", k = 2)

# Selección con BIC
modelo_step_bic <- step(modelo_completo, direction = "backward", k = log(nrow(df_sin_democracia_sin_na)))

```

En la selección según AIC, el modelo presenta un AIC final de -1590.3, donde no se excluye ninguna variable. Por su parte, en la selección según BIC, en la que se penalizan más los modelos complejos, el modelo óptimo presenta un BIC de -1554, descartando `generosity`. El hecho de que ambos modelos no coincidan muestra que el modelo no es lo suficientemente robusto frente a cambios en la penalización por complejidad; lo cual nos puede llevar a problemas con nuestros datos longitudinales, y consolida la necesidad de emplear métodos más adecuados para esta estructura como los modelos mixtos.

### Estrategia bottom-up (forward selection)

También incorporamos una estrategia bottom-up (selección hacia adelante), que parte de un modelo nulo y añade variables una a una en función de la mejora del AIC. Esta estrategia permite comprobar si existe alguna combinación alternativa de predictores que produzca un modelo competitivo o incluso mejor al obtenido por eliminación hacia atrás.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Modelo nulo y completo
modelo_nulo <- lm(happiness_score ~ 1, data = df_sin_democracia_sin_na)
modelo_completo <- lm(happiness_score ~ gdp + life_exp + support + freedom + generosity + corruption, data = df_sin_democracia_sin_na)

# Forward selection
modelo_step_forward <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_completo), direction = "forward")

```

En este caso, se fueron incorporando variables hasta alcanzar el modelo completo, es decir, con todas las variables explicativas. Este resultado coincide con el modelo obtenido por backward elimination por AIC, pero difiere en el seleccionado por BIC ya que este descartaba `generosity`. Esta diferencia muestra que los criterios de selección pueden llevar a soluciones distintas según el punto de partida.

### Diagnóstico y validación final del modelo

En base a los resultados anteriores, el modelo final que utilizaremos para el diagnóstico y validación es el siguiente: 
$$
happiness\_score_{ij} = \beta_0 + \beta_1\,gdp_{ij} + \beta_2\,life\_exp_{ij} + \beta_3\,support_{ij} + \beta_4\,freedom_{ij} + \beta_5\,corruption_{ij} + \epsilon_{ij}.
$$ 
```{r message=FALSE, warning=FALSE, echo=FALSE}
# Modelo nulo y completo
modelo_nulo <- lm(happiness_score ~ 1, data = df_sin_democracia_sin_na)
modelo_completo <- lm(happiness_score ~ gdp + life_exp + support + freedom + generosity + corruption, data = df_sin_democracia_sin_na)

# Forward selection
modelo_step_forward <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_completo), direction = "forward")

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Cargar librería necesaria
library(car)

# Modelo con todas las explicativas como predictores
modelo_vif_total <- lm(happiness_score ~ gdp + life_exp + support + freedom + corruption, 
                       data = df_sin_democracia_sin_na)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Calcular VIF de cada predictor
vif <- vif(modelo_vif_total)
gdp <- vif["gdp"]
life_exp <- vif["life_exp"]
support <- vif["support"]
freedom <- vif["freedom"]
corruption <- vif["corruption"]
```

Para comprobar que no tenemos problemas de multicolinealidad, calcularemos el VIF del modelo. Podemos confirmar que, en efecto, ninguna de nuestras variables genera grandes problemas de multicolinealidad (**1.853, 1.957, 1.893, 1.295, 1.144**), ya que no contamos con ningún valor de VIF superior a 2. Como veremos en la siguiente sección, ahora procederemos a realizar el diagnóstico y validación final del modelo, verificando si cumple con las hipótesis necesarias para garantizar dicha validez. Estas hipótesis incluyen:

-   Normalidad de los residuos.

-   Media cero de los residuos.

-   Homoscedasticidad (varianza constante de los errores).

-   Independencia de los errores.

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-modelo-clasico
#| echo: false
#| warning: false
#| fig-cap: "Gráficas para la validación del modelo clásico."
#| fig-width: 5
#| fig-height: 3.5
modelo_final <- lm(happiness_score ~ support + life_exp + freedom + gdp + corruption,
                   data = df_sin_democracia_sin_na)
autoplot(modelo_final, which = 1:4)

```

#### Normalidad de los residuos

Si observamos el gráfico Q-Q de la @fig-modelo-clasico, llega un momento en el que los residuos se desvían de la línea teórica. No obstante, aplicamos el test de Jarque-Bera para evaluar de forma numérica si los residuos del modelo siguen una distribución normal. El resultado indica un p-valor muy bajo (**\<0.001**), lo que nos lleva a rechazar la hipótesis de normalidad.

```{r message=FALSE, warning=FALSE, include=FALSE}
jarque.bera.test(modelo_final$residuals)
jarque <- jarque.bera.test(modelo_final$residuals)$p.value
```

#### Media cero

De la misma manera, podemos calcular de forma numérica la media de los residuos para verificar si se aproxima a cero, como requiere el modelo. En este caso, se cumple adecuadamente (**0**). Sin embargo, esta no es la forma correcta de determinar la media cero de los residuos, sino que hay que hacer una interpretación gráfica. Si observamos la gráfica Residuals vs Fitted en la @fig-modelo-clasico, podríamos decir que los valores más bajos se alejan del eje de abscisas, por lo que se cumple los residuos no tienen media cero.

```{r message=FALSE, warning=FALSE, include=FALSE}
mean(modelo_final$residuals)
```

#### Homoscedasticidad

El gráfico de residuos frente a los valores ajustados de la @fig-modelo-clasico muestra cierta dispersión irregular, por lo que podría haber heterocedasticidad. Para comprobarlo de forma numérica, se aplica la prueba de Breusch-Pagan para comprobar si la varianza de los errores es constante. El resultado del test devuelve un p-valor muy bajo (**\<0.001**), lo que sugiere que, efectivamente, no hay varianza constante.

```{r message=FALSE, warning=FALSE, include=FALSE}
bptest(modelo_final, studentize = FALSE)

```

#### No correlación de los errores

Si observamos la gráfica Residuals vs Fitted en la @fig-modelo-clasico, podemos observar una cierta curva que nos pueda hacer pensar que los errores están correlacionados. Mediante el test de Durbin-Watson, verificamos de forma numérica que no exista esta autocorrelación en los residuos. En este caso, el p-valor vuelve a ser muy bajo (**\<0.001**), lo que nos hace rechazar la hipótesis nula y, por tanto, ver que existe autocorrelación de los errores.

```{r message=FALSE, warning=FALSE, include=FALSE}
dwtest(modelo_final)

```

#### Conclusión del diagnóstico

Estos incumplimientos de los supuestos teóricos sugieren que el modelo no es válido para trabajar con datos longitudinales. La inadecuación del modelo clásico justifica el uso de modelos más robustos capaces de incorporar la estructura jerárquica de los datos, como los modelos lineales mixtos (LMM), los cuales permiten modelar efectos aleatorios por país, capturar la correlación entre medidas repetidas y mejorar la validez e interpretación de los resultados. 

## Modelos Lineales Mixtos (LMM)

En el modelado clásico mediante regresión lineal múltiple asumimos que las observaciones eran independientes entre sí, pero en nuestro caso trabajamos con datos longitudinales, es decir, con medidas repetidas a lo largo del tiempo. Esto conlleva a una dependencia entre observaciones que los modelos clásicos no pueden capturar adecuadamente, y para afrontar esta limitación recurrimos a los modelos lineales mixtos (LMM). 

Los LMM permiten combinar efectos fijos, que capturan el efecto promedio de las variables explicativas sobre la variable respuesta, y efectos aleatorios, que permiten modelar la variabilidad específica entre países. De esta forma podemos capturar la estructura jerárquica de los datos, considerando que cada país puede tener un nivel base de felicidad distinto (intercepto propio), mientras que los efectos de las variables predictoras son comunes a todos los países. En nuestro modelo, consideramos efectos fijos aquellas variables explicativas cuyo efecto queremos estimar de forma general para toda la población (en este caso, todos los países y años). Estas variables incluyen `gdp`, `support`, `freedom`, `life_exp`, `corruption` y las variables políticas (`is_democracy`, `regime_category`, etc.). También introducimos un intercepto aleatorio por país porque cada país tiene un nivel base distinto de felicidad no explicado por las variables fijas, hay dependencia entre observaciones del mismo país en distintos años, y no nos interesa estimar el efecto específico de cada país, sino tener en cuenta la variabilidad entre ellos. Además, se incorpora también `year` como efecto aleatorio, ya que se asume que la evolución temporal del `Happiness Score` no es idéntica en todos los países, ya que algunos pueden experimentar mejoras sostenidas a lo largo del tiempo, mientras que otros pueden estancarse o incluso empeorar. Permitir que la relación con el tiempo varíe entre países nos ayuda a modelar mejor esta variabilidad en las evoluciones temporales, respetando la estructura longitudinal de los datos. El modelo lineal mixto que vamos a plantear incluye todas las variables de nuestra base de datos como efectos fijos ya que vamos a asumir que todas tienen influencia en la felicidad. Nuestro LMM es el siguiente: \begin{align*}
happinessscore_{ij} =\ & \beta_0 
+ \beta_1 \cdot regionalindicator_{ij}
+ \beta_2 \cdot \text{gdp}_{ij}
+ \beta_3 \cdot \text{support}_{ij}
+ \beta_4 \cdot lifeexp_{ij} \\
&+ \beta_5 \cdot \text{freedom}_{ij} 
+ \beta_6 \cdot \text{generosity}_{ij}
+ \beta_7 \cdot \text{corruption}_{ij}
+ \beta_8 \cdot \text{status}_{ij} \\
&+ \beta_9 \cdot politicalrights_{ij} 
+ \beta_{10} \cdot civilliberties_{ij}
+ \beta_{11} \cdot fairelection_{ij} \\
&+ \beta_{12} \cdot regimecategory_{ij} 
+ \beta_{13} \cdot \text{democracy}_{ij} 
+ \beta_{14} \cdot electoralcategory_{ij} \\
&+ \beta_{15} \cdot \text{presidential}_{ij}
+ \beta_{16} \cdot \text{alternation}_{ij}
+ \beta_{17} \cdot \text{year}_{ij} \\
&+ u_{0i} + u_{1i} \cdot \text{year}_{ij}
+ \varepsilon_{ij}.
\end{align*}

donde:

-   $i$ representa el país y $j$ el año.

-   $\beta_k$ son los coeficientes fijos asociados a cada variable explicativa.

-   $u_{0i} \sim \mathcal{N}(0, \sigma_{u0}^2)$ es el intercepto aleatorio por país.

-   $u_{1i} \sim \mathcal{N}(0, \sigma_{u1}^2)$ es el efecto aleatorio asociado al año dentro de cada país.

-   $\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2)$ es el término de error residual.

Para seleccionar el mejor modelo, partimos del modelo mixto completo y generamos múltiples modelos candidatos con diferentes combinaciones de variables predictoras. Iniciamos una búsqueda automática que identifica los modelos con mejor equilibrio entre ajuste y complejidad, evaluado mediante el AIC. Recordemos que para comparar modelos con distintos efectos fijos, necesitamos ajustar el modelo inicial utilizando máxima verosimilitud (ML) en lugar de REML, ya que REML se utiliza cuando la estructura de efectos fijos es la misma. De esta manera, generamos una lista de modelos candidatos ordenados por su AIC, de manera que si el primer modelo de la lista no resulta válido en nuestro futuro diagnóstico, pasamos al siguiente modelo de la lista; y así suvesivamente hasta que encontremos un LMM válido. A continuación, se muestra la salida del LMM:

```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)

# Leer los datos 
df_happiness <- read.csv("df_sin_democracia_sin_na.csv")
df_politicas <- read.csv("df_completo_sin_na.csv")

# Variables políticas que se quieren mantener fijas desde 2020
vars_politicas <- c("fair_election", "regime_category", "democracy",
                    "electoral_category", "presidential", "alternation")

# Extraer valores de 2020 para esas variables
politicas_2020 <- df_politicas %>%
  filter(year == 2020) %>%
  select(country, all_of(vars_politicas))

# Filtrar df_happiness solo para países que tienen datos políticos válidos
paises_validos <- unique(politicas_2020$country)
df_happiness_filtrado <- df_happiness %>%
  filter(country %in% paises_validos)

# Expandir datos políticos de 2020 a todos los años
años <- 2015:2024
base_expansion <- expand.grid(country = paises_validos, year = años)

politicas_expandido <- base_expansion %>%
  left_join(politicas_2020, by = "country")

# Unir ambas fuentes para crear el dataframe completo
df_unificado <- df_happiness_filtrado %>%
  left_join(politicas_expandido, by = c("country", "year"))

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Cargar librerías necesarias
library(lme4)
library(MuMIn)
library(DHARMa)

# Ajustar el modelo base para selección 
modelo_base <- lmer(
  happiness_score ~ regional_indicator + gdp + support + life_exp + freedom + 
    generosity + corruption + status + political_rights + civil_liberties +
    fair_election + regime_category + democracy + electoral_category + 
    presidential + alternation + year +
    (1 + year | country),
  data = df_unificado,
  REML = FALSE,
  na.action = na.fail
)

# Aplicar selección por AIC
# modelos_dredge <- dredge(modelo_base, trace = FALSE)
# modelo_seleccionado <- get.models(modelos_dredge, 1)[[1]]
modelo_seleccionado <- modelo_base <- lmer(
  happiness_score ~ civil_liberties + electoral_category + freedom +  
    gdp + life_exp + political_rights + regime_category + regional_indicator +  
    status + support + year + (1 + year | country),
  data = df_unificado,
  REML = FALSE,
  na.action = na.fail
)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(lme4)
formula(modelo_seleccionado)
summary(modelo_seleccionado)$coefficients
# fixef(modelo_seleccionado)      # Efectos fijos
# ranef(modelo_seleccionado)      # Efectos aleatorios
# VarCorr(modelo_seleccionado)


```

La salida del modelo mixto lineal seleccionado muestra un ajuste con un gran número de efectos fijos y un efecto aleatorio de año por país, lo que permite capturar variaciones estructurales tanto entre países como a lo largo del tiempo. En concreto, el modelo es el siguiente: \begin{align*}
happinessscore_{ij} =\ & \beta_0 
+ \beta_1 \cdot civilliberties_{ij}
+ \beta_2 \cdot electoralcategory_{ij}
+ \beta_3 \cdot \text{freedom}_{ij} \\
&+ \beta_4 \cdot \text{gdp}_{ij}
+ \beta_5 \cdot lifeexp_{ij}
+ \beta_6 \cdot politicalrights_{ij} \\
&+ \beta_7 \cdot regimecategory_{ij} 
+ \beta_8 \cdot regionalindicator_{ij}
+ \beta_9 \cdot \text{status}_{ij} \\
&+ \beta_{10} \cdot \text{support}_{ij}
+ \beta_{11} \cdot \text{year}_{ij} 
+ u_{0j} + u_{1j} \cdot \text{year}_{ij}
+ \epsilon_{ij}.
\end{align*} Entre los efectos fijos, se observa que `support`, `life_exp` y especialmente `freedom` tienen efectos positivos y estadísticamente significativos sobre el nivel de felicidad, lo que indica que mayores niveles de libertad para tomar decisiones, esperanza de vida y apoyo social están fuertemente asociados con una mayor puntuación de felicidad. También destaca el indicador regional North America and ANZ, con un coeficiente positivo y significativo, lo que indica que esta región tiene niveles de felicidad altos, mientras que otras regiones como South Asia o Sub-Saharan Africa presentan efectos negativos y significativos, evidenciando una menor felicidad media en esas áreas. Dentro de las variables políticas, el régimen de Military dictatorship tiene un efecto negativo relevante, mientras que el statusPF (partly free) tiene un efecto positivo aunque de menor magnitud. En definitiva, el modelo explica adecuadamente la variabilidad de la felicidad teniendo en cuenta factores estructurales, económicos, sociales y políticos.

Para evaluar la calidad del modelo, utilizaremos las siguientes medidas: el R² marginal, que representa la proporción de varianza explicada por los efectos fijos, y el R² condicional, que representa proporción de varianza explicada por todo el modelo.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(performance)
# Calcular R²
r2_vals <- r2(modelo_seleccionado)

# Extraer el R² marginal
r2_marginal <- r2_vals$R2_marginal

# Extraer el R² condicional
r2_conditional <- r2_vals$R2_conditional
```

En concreto, el R² marginal es de **`r round(r2_marginal, 3)`**, lo que significa que aproximadamente el 70.2% de la varianza total en la felicidad se explica exclusivamente por los efectos fijos del modelo, es decir, por las variables explicativas como `freedom`, `support`, `life_exp` o `civil_liberties`. Por otro lado, el R² condicional asciende hasta **`r round(r2_conditional, 3)`**, lo que implica que si además se consideran los efectos aleatorios, en este caso las variaciones específicas de cada país con el año, el modelo es capaz de explicar el 93.2% de la varianza total del Happiness Score; mostrando que nuestro modelo explica mucha de la variación de la puntuación felicidad. No obstante, esta gran diferencia de más del 20% entre el R² marginal y condicional demuestra que la variabilidad no explicada por los efectos fijos pero capturada por los efectos aleatorios juega un papel clave en la explicación de la felicidad. En conjunto, estos resultados consolidan el poder explicativo del modelo, y que tanto las variables medidas como la modelización de la variabilidad de la felicidad a partir del año contribuyen significativamente a entender las diferencias en los niveles de felicidad.

Como en cualquier modelo estadístico, es esencial verificar que las suposiciones sobre los residuos se cumplen también en el contexto de modelos mixtos. En particular, evaluamos la normalidad de los residuos, la homocedasticidad y proporción de valores atípicos. Para ello, se utilizan gráficos similares a los del modelo clásico, pero adaptados a la estructura jerárquica de los datos. Para validar los supuestos del modelo, se utiliza la función `testResiduals()` del paquete `DHARMa`[@dharma]. Esta función genera residuos simulados a partir del modelo ajustado, y los compara con los residuos observados; evaluando tres aspectos fundamentales de los residuos. Primero, la uniformidad, ya que verifica si los residuos simulados siguen una distribución uniforme, lo que sería esperable bajo un modelo bien planteado; basándose en el test de Kolmogorov–Smirnov. Segundo, la dispersión, evaluando la distribución de los residuos comparando la variabilidad observada con la esperada. Y por último, los valores atípicos, porque detecta si hay un número de outliers mayor al esperado bajo el modelo; utilizando una prueba binomial para estimar su proporción.

```{r}
#| label: fig-qqplot-residuos2
#| echo: false
#| warning: false
#| fig-cap: "QQ-plot de los residuos simulados del modelo mixto."
#| fig-width: 5
#| fig-height: 3.5

sim_res <- DHARMa::simulateResiduals(fittedModel = modelo_seleccionado)
```

```{r}
#| label: fig-dispersion-residuos2
#| echo: false
#| warning: false
#| fig-cap: "Dispersión de los residuos simulados frente a los valores predichos."
#| fig-width: 5
#| fig-height: 3.5

plotResiduals(sim_res)
```

```{r}
#| label: fig-test-residuos2
#| echo: false
#| warning: false
#| fig-cap: "Resultados del test formal de uniformidad aplicado a los residuos simulados."

testResiduals(sim_res)
```

### Normalidad

El gráfico QQ-plot de la @fig-test-residuos2 muestra una alineación bastante ajustada de los residuos simulados con la línea teórica, lo que sugiere una distribución aproximadamente normal. Aunque se observan ligeras desviaciones en las colas, el test de Kolmogorov-Smirnov aplicado a los residuos proporciona un p-valor de **0.069**, lo que indica que no se puede rechazar la hipótesis nula de normalidad. Por tanto, los residuos sugieren normalidad y el modelo cumple satisfactoriamente con este supuesto.

### Homocedasticidad

En el gráfico de residuos frente a valores ajustados de la @fig-dispersion-residuos2, la nube de puntos es dispersa y no se detecta ninguna tendencia aparente. El test de dispersión de DHARMa refuerza esta conclusión con un p-valor de **0.512**, indicando que no existen evidencias significativas de heterocedasticidad. La varianza de los residuos puede considerarse homogénea, por lo que el modelo cumple también con el supuesto de homocedasticidad.

### Outliers y estructura de los residuos

En cuanto a los outliers, el gráfico de residuos simulados frente a predicciones de la @fig-test-residuos2 revela ciertas desviaciones en los cuantiles (indicadas por las líneas rojas), pero si nos fijamos en el test binomial, se estima una proporción de **0.012** de observaciones extremas (17 de 1421), que no difiere significativamente de la esperada por azar (**0.008**). Esto implica que la presencia de valores extremos no es problemática, y como podemos ver, el p-valor es de **0.098**, por lo que el número de outliers no es estadísticamente preocupante.

### Conclusión del diagnóstico

El diagnóstico general indica que el modelo cumple de forma razonable con los tres supuestos clave: normalidad, homocedasticidad y proporción esperada de outliers; por lo que se puede considerar estadísticamente fiable para la inferencia y predicción del Happiness Score. Esta validación respalda la solidez del modelo ajustado y su utilidad para explicar las variaciones en la felicidad a partir de las variables seleccionadas.

### Predicción del Happiness Score para 2025

Usando el modelo mixto ajustado, se pueden obtener predicciones personalizadas por país; lo que permite construir un ranking proyectado de felicidad para 2025.

```{r message=FALSE, warning=FALSE, include=FALSE}
# Cargar librerías necesarias
library(lme4)
library(dplyr)

# Crear una copia de la base de datos para 2025
datos_2025 <- df_unificado

# Sustituimos el valor del año por 2025 en todas las observaciones
datos_2025$year <- 2025

# Realizamos la predicción utilizando el modelo mixto
# allow.new.levels = TRUE permite predecir incluso si hay países nuevos o no observados
datos_2025$happiness_pred_2025 <- predict(modelo_seleccionado, newdata = datos_2025, allow.new.levels = TRUE)

# Agrupar por país y calcular la media de felicidad predicha en 2025 (si hay varias filas por país)
ranking_2025 <- datos_2025 %>%
  group_by(country) %>%
  summarise(happiness_pred_2025 = mean(happiness_pred_2025, na.rm = TRUE)) %>%
  arrange(desc(happiness_pred_2025)) %>%
  mutate(rank = row_number())

# Mostrar top 10
print(head(ranking_2025, 10))

# Mostrar bottom 10
print(tail(ranking_2025, 10))

ranking_2025 %>% 
  filter(country == "Spain")

ranking_2024 <- df_unificado %>%
  filter(year == 2024) %>%
  select(country, happiness_score) %>%
  arrange(desc(happiness_score)) %>%
  mutate(rank_2024 = row_number())

ranking_2024 %>%
  filter(country == "Spain")


```

```{r message=FALSE, warning=FALSE, include=FALSE}
#| label: tabla1
library(dplyr)
library(knitr)

# Unir rankings de 2024 y 2025
comparativa <- left_join(ranking_2025, ranking_2024, by = "country") %>%
  rename(score_2025 = happiness_pred_2025,
         score_2024 = happiness_score) %>%
  select(country, score_2025, rank, score_2024, rank_2024)

# Top 10
top_10 <- comparativa %>% slice_min(rank, n = 10) %>% 
  mutate(section = "Top 10")

# España sola
espana <- comparativa %>% 
  filter(country == "Spain") %>%
  mutate(section = "España")

# Bottom 10
bottom_10 <- comparativa %>% slice_max(rank, n = 10) %>%
  mutate(section = "Bot 10")

# Unir todo
tabla_final <- bind_rows(top_10, espana, bottom_10) %>%
  arrange(factor(section, levels = c("Top 10", "España", "Bot 10")), rank)

# Mostrar como tabla
kable(tabla_final, caption = "Comparación del ranking de felicidad en 2025 y 2024 (Top, España, Bottom)",
      col.names = c("País", "Score 2025", "Ranking 2025", "Score 2024", "Ranking 2024", "Sección"))

```

```{r}
#| label: tbl-ranking-2024
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Comparación del ranking de felicidad en 2025 y 2024 (Top, España, Bottom)"
#| tbl-columns: 8

kable(tabla_final,
      col.names = c("País", "Score 2025", "Ranking 2025", "Score 2024", "Ranking 2024", "Sección"))

```

Lo primero que podemos observar en la [@tbl-ranking-2024] es que los países nórdicos continúan liderando el ranking global del Happiness Score estimado para 2025. Se observa que Finlandia encabeza el ranking con una predicción de 7.75 puntos, consolidando su posición como líder mundial en felicidad global. Le siguen Dinamarca (7.61), Islandia (7.52) y Países Bajos (7.42), todos cerca de su posición en 2024, lo que demuestra cierta estabilidad en su calidad de vida. El top 10 lo completan Suiza, Noruega, Suecia, Israel, Nueva Zelanda y Luxemburgo, todos con puntuaciones superiores a 7.2.

En el extremo opuesto del ranking, los países con los niveles más bajos de felicidad prevista son Afganistán, que ocupa el último puesto con un valor de 2.54, seguido por Sudán del Sur, República Centroafricana y Zimbabue; países que destacan por presentar conflictos, pobreza o inestabilidad política. Todas las puntuaciones están por debajo de 3.6, lo que refleja condiciones estructurales desfavorables que impactan fuertemente de forma negativa en la felicidad.

Si nos fijamos en España, obtiene un Happiness Score previsto de 6.42, situándose en la posición 28; una posición que está por encima de la media. Aunque no alcanza los niveles nórdicos, se encuentra en el tercio superior del ranking, lo que implica una posición destacada entre los países con mayor felicidad y bienestar. Aunque la puntuación de felicidad predicha para España en 2025 es la misma que para 2024, la posición en el ranking mejora: sube del puesto 35 al 28. Esto implica que otros países han bajado más que España, permitiendo su ascenso en el ranking a pesar de una leve caída en su puntuación; un buen ejemplo de cómo el ranking no depende únicamente de la puntuación, sino también del entorno de comparación entre países.

## Desarrollo del Modelo Lineal Generalizado Mixto (GLMM)

En este apartado buscamos una alternativa al modelo lineal mixto mediante un modelo lineal generalizado mixto (GLMM). Este tipo de modelos permite suavizar el supuesto de normalidad de los residuos, lo que nos sirve de ayuda cuando la variable dependiente presenta asimetría. Como el Happiness Score es una variable positiva y su distribución es ligeramente asimétrica hacia la derecha, utilizaremos una distribución Gamma con enlace logarítmico.

A diferencia del modelo lineal mixto anterior, en este caso haremos una búsqueda automática de modelos válidos combinando variables candidatas en distintos subconjuntos. El principal motivo por el que no utilizamos el mismo modelo que para LMM es que no encontramos ningún GLMM que fuese válido con `year` como efecto aleatorio; por lo que consideramos que utilizar `regional_indicator` también sería coherente para nuestro estudio. Para cada combinación validamos el modelo ajustado aplicando los tests de DHARMa sobre los residuos simulados, exigiendo que se superen todos los test.

El primer modelo válido cuenta con dos efectos fijos: `support` (apoyo social percibido) y `life_exp` (esperanza de vida). En concreto, el modelo es el siguiente: $$
\text{Happiness}_{ij} \sim \text{Gamma}(\mu_{ij}, \theta)
$$ $$
\log(\mu_{ij}) = \beta_0 + \beta_1 \cdot \text{support}_{ij} + \beta_2 \cdot lifeexp_{ij} + u_{0i} + u_{1i} \cdot regionalindicator_{ij}.
$$ donde:

-   $\mu_{ij}$ es la esperanza del nivel de felicidad del país $i$ en el año $j$.
-   $\beta_0, \beta_1, \beta_2$ son los efectos fijos.
-   $u_{0i}, u_{1i}$ son los efectos aleatorios asociados al país $i$ en función de `regional_indicator`.
-   El término $\log(\mu_{ij})$ indica que se está usando un link logarítmico.

Aunque hemos explorado cientos de combinaciones de variables explicativas posibles para ajustar un modelo lineal generalizado mixto (GLMM) válido, ninguno de los modelos obtenidos ha devuelto un valor definido para el AIC: en todos los casos, esta métrica ha aparecido como NA (Not Available). El AIC, para que pueda calcularse correctamente, requiere que todos los componentes del modelo hayan sido estimados de forma numéricamente estable. Este problema puede haberse dado debido a que, al contar con todos los países, estamos trabajando con estructuras complejas y variables que pueden estar altamente correlacionadas, lo que hace que la variabilidad entre regiones lleve a problemas de redundancia o que la combinación de efectos tenga singularidad. Es importante destacar que el hecho de que el AIC sea NA no implica que el modelo no sea válido, sino que no se puede evaluar su calidad frente a otros modelos. Para priorizar la validez estadística del modelo, optamos por aceptar modelos con AIC NA aunque registremos esta limitación. A continuación, se muestra la salida del GLMM:

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Cargar librerías necesarias
library(glmmTMB)
library(MuMIn)
library(DHARMa)
library(tidyverse)

# Modelo GLMM válido
glmm_valido <- glmmTMB(
  happiness_score ~ support + life_exp + (1 + regional_indicator | country),
  data = df_unificado,
  family = Gamma(link = "log"),
  na.action = na.fail
)
summary(glmm_valido)

```

Entre los efectos fijos, observamos que tanto `support` como `life_exp` tienen efectos positivos y altamente significativos sobre el nivel de felicidad (**\<0.001**). El coeficiente de `support` es de **0.2141**, lo que implica que, manteniendo constantes el resto de variables, un incremento de una décima en el nivel de apoyo social está asociado con un incremento de un 2.2% (exp(0.02141) = 1.022) en el valor esperado del Happiness Score; consolidando la idea de que aumento del apoyo social está asociado al aumento de la felicidad. Por su parte, el coeficiente de `life_exp` es de **0.00207**, lo que significa que por cada año que aumente la esperanza de vida, la felicidad aumenta en torno a un 0.2%; teniendo un impacto menor que el apoyo social pero demostrando que la longevidad y una buena sanidad están positivamente relacionadas con la felicidad. En cuanto a los efectos aleatorios, observamos que la varianza del intercepto entre países (**0.01104**) nos indica que existen todavía diferencias entre países que afectan al nivel de felicidad y que no son explicadas por los efectos fijos del modelo. Si observamos el resto de varianzas, vemos que hay algunas cercanas a 0, como es el caso de Sudamérica; lo cual explica el motivo por el que hemos obtenido un AIC de NA: hay valores cercanos a 0 que hacen que la matriz de varianzas-covarianzas sea singular y no tenga estabilidad numérica. Por último, el modelo presenta un estimador de dispersión ($\sigma^2$) de **0.00503**, lo que indica una baja variabilidad residual y, por tanto, un buen ajuste. En general, este modelo GLMM permite plasmar de forma eficaz la relación entre felicidad y otros factores como el apoyo social y la esperanza de vida, teniendo en cuenta variabilidad específica entre regiones. 

```{r message=FALSE, warning=FALSE, include=FALSE}
library(performance)
r2(glmm_valido)
```

Se ha calculado el R² marginal para el modelo GLMM, obteniendo un valor de **0.387**, lo que indica que los efectos fijos del modelo explican aproximadamente el 38.7% de la varianza del Happiness Score. Sin embargo, no ha sido posible calcular el R² condicional debido a que hay componentes de los efectos aleatorios que tienen varianzas cercanas a cero (como es el caso de Sudamérica), lo que genera problemas de singularidad. Este suceso, si bien no nos permite ver del todo la calidad del modelo, no compromete su validez en términos de significancia y ajuste, pero limita la interpretación del componente aleatorio. Al igual que hicimos antes, vamos a comprobar que este modelo es válido para poder hacer predicciones.

```{r}
#| label: fig-qqplot-residuos3
#| echo: false
#| warning: false
#| fig-cap: "QQ-plot de los residuos simulados del modelo mixto."
#| fig-width: 5
#| fig-height: 3.5

sim_res <- DHARMa::simulateResiduals(fittedModel = glmm_valido)
```

```{r}
#| label: fig-dispersion-residuos3
#| echo: false
#| warning: false
#| fig-cap: "Dispersión de los residuos simulados frente a los valores predichos."
#| fig-width: 5
#| fig-height: 3.5

plotResiduals(sim_res)
```

```{r}
#| label: fig-test-residuos3
#| echo: false
#| warning: false
#| fig-cap: "Resultados del test formal de uniformidad aplicado a los residuos simulados."

testResiduals(sim_res)
```

### Normalidad de residuos

El gráfico QQ-plot de la @fig-test-residuos3 muestra una alineación bastante razonable con la línea diagonal, sin desviaciones aparentes. El test de Kolmogorov-Smirnov nos da un p-valor de **0.071**, lo que indica que no podemos rechazar la hipótesis de uniformidad, y, por tanto, cumple el supuesto de normalidad.

### Homocedasticidad

El gráfico de residuos frente a predicciones de la @fig-dispersion-residuos3 no muestra ningún tipo de tendencia aparente en la dispersión, por lo que gráficamente no parece haber evidencia de heterocedasticidad. En el test de dispersión obtenemos un p-valor de **0.176**, confirmando que no hay evidencias para rechazar la hipótesis de homocedasticidad; cumpliendo con el supuesto.

### Outliers y estructura de los residuos

El gráfico de residuos frente a valores ajustados de la @fig-test-residuos3 muestra que hay una parte muy pequeña de observaciones que se desvía del comportamiento esperado, y numéricamente a través del test binomial, que detecta 7 outliers en un total de 1421 observaciones (porporción de **0.005**), vemos que el p-valor obtenido es de **0.233**, lo que indica que la proporción de valores atípicos no significativamente de la proporción esperada; por lo que no hay evidencias de que los outliers estén afectando de manera preocupante al modelo.

### Conclusión del modelo GLMM

Este modelo GLMM, a pesar de tener ciertos problemas de singularidad, ha demostrado a través de su diagnóstico que tiene un ajuste razonable y estadísticamente válido. La interpretación de los efectos fijos confirma que tanto el apoyo social como la esperanza de vida son variables explicativas que tienen un impacto positivo en la felicidad, lo cual es coherente con la teoría y con los resultados del modelo LMM. El modelo GLMM ofrece una alternativa al LMM cuando queremos modelar la variable objetivo sin asumir distribución normal, y demuestra ser un método fiable a la hora de querer estimar la felicidad global.

### Predicción del Happiness Score para 2025

Al igual que en el modelo lineal mixto, utilizaremos nuestro modelo GLMM para estimar la felicidad en 2025.
```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(knitr)

# Crear copia para predicciones LMM
datos_2025_lmm <- df_unificado
datos_2025_lmm$year <- 2025

# Predecir con el modelo LMM
datos_2025_lmm$happiness_pred_2025_lmm <- predict(modelo_seleccionado, newdata = datos_2025_lmm, allow.new.levels = TRUE)

# Crear ranking LMM
ranking_lmm_2025 <- datos_2025_lmm %>%
  group_by(country) %>%
  summarise(score_2025_lmm = mean(happiness_pred_2025_lmm, na.rm = TRUE)) %>%
  arrange(desc(score_2025_lmm)) %>%
  mutate(rank_lmm = row_number())

# Crear copia para predicciones GLMM
datos_2025_glmm <- df_unificado
datos_2025_glmm$year <- 2025

# Predecir con el modelo GLMM
datos_2025_glmm$happiness_pred_2025_glmm <- predict(glmm_valido, newdata = datos_2025_glmm, type = "response", allow.new.levels = TRUE)

# Crear ranking GLMM
ranking_glmm_2025 <- datos_2025_glmm %>%
  group_by(country) %>%
  summarise(score_2025_glmm = mean(happiness_pred_2025_glmm, na.rm = TRUE)) %>%
  arrange(desc(score_2025_glmm)) %>%
  mutate(rank_glmm = row_number())

ranking_2024 <- df_unificado %>%
  filter(year == 2024) %>%
  group_by(country) %>%
  summarise(score_2024 = mean(happiness_score, na.rm = TRUE)) %>%
  arrange(desc(score_2024)) %>%
  mutate(rank_2024 = row_number())

library(knitr)

# Unir todos los rankings por país
comparativa_total <- ranking_lmm_2025 %>%
  left_join(ranking_glmm_2025, by = "country") %>%
  left_join(ranking_2024, by = "country")

# Top 10, España, Bottom 10 (según LMM)
top_10 <- comparativa_total %>% slice_min(rank_glmm, n = 10) %>% mutate(section = "Top 10")
espana <- comparativa_total %>% filter(country == "Spain") %>% mutate(section = "España")
bottom_10 <- comparativa_total %>% slice_max(rank_glmm, n = 10) %>% mutate(section = "Últimos 10")

# Unir top 10, España y bottom 10
tabla_final <- bind_rows(top_10, espana, bottom_10) %>%
  # Reordenar columnas para mostrar primero GLMM, luego LMM
  select(country,
         score_2025_glmm, rank_glmm,
         score_2025_lmm, rank_lmm,
         score_2024, rank_2024,
         section) %>%
  # Ordenar por sección y ranking GLMM
  arrange(factor(section, levels = c("Top 10", "España", "Últimos 10")), rank_glmm)

# Unir todo y mostrar
tabla_final <- tabla_final %>%
  select(country,
         score_2025_glmm, rank_glmm,
         score_2025_lmm, rank_lmm,
         score_2024, rank_2024,
         section) %>%
  arrange(factor(section, levels = c("Top 10", "España", "Últimos 10")), rank_glmm)

kable(tabla_final,
      caption = "Comparación del ranking de felicidad en 2025 (LMM y GLMM) y 2024",
      col.names = c("País", "Score 2025 (GLMM)", "Ranking 2025 (GLMM)",
                    "Score 2025 (LMM)", "Ranking 2025 (LMM)",
                    "Score 2024", "Ranking 2024", "Sección"))


```

```{r}
#| label: tbl-ranking-2025
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Comparación del ranking de felicidad en 2025 (LMM y GLMM) y 2024"
#| tbl-columns: 8

kable(tabla_final,
      col.names = c("País", "Score 2025 (GLMM)", "Ranking 2025 (GLMM)",
                    "Score 2025 (LMM)", "Ranking 2025 (LMM)",
                    "Score 2024", "Ranking 2024", "Sección"))

```

Los resultados de la predicción de la [@tbl-ranking-2025] muestran que los países nórdicos siguen liderando el ranking de felicidad mundial: Finlandia encabeza la lista con una puntuación estimada de 7.63, seguida por Dinamarca (7.54), Islandia (7.48) y Noruega (7.42). Otros países del top 10 incluyen a Suiza, Países Bajos, Suecia, Nueva Zelanda, Israel y Australia, todos con puntuaciones por encima de 7.1; contando con prácticamente los mismos países que el modelo LMM, aunque difieren en alguna posición.

En contraste, los países con las puntuaciones más bajas en felicidad predicha para 2025 son Afganistán (2.86), República Centroafricana (3.23), Burundi (3.30), Sudán del Sur (3.30), y Ruanda (3.42). Al igual que antes, estos países se caracterizan por tener confictos, inestabilidad política y pobreza, lo que afecta de forma negativa a su felicidad.

En cuanto a España, se predice un Happiness Score de 6.39 para 2025, lo que la sitúa en la posición 31 del ranking mundial. Esta puntuación representa una ligera reducción respecto al año anterior (6.42), pero supone una mejora en la clasificación, ya que sube del puesto 35 al 31. Esta subida refleja que, aunque la puntuación de España haya sufrido una pequeña bajada, otros países han experimentado caídas mayores, permitiendo que España ascienda en el ranking relativo. 

Estos resultados señalan que incluso un modelo con solo dos variables explicativas como lo son el apoyo social y la esperanza de vida puede comprender de forma significativa las diferencias en felicidad entre países. Además, las predicciones realizadas con este GLMM son coherentes con las tendencias observadas, y consolidan al apoyo social y a la esperanza de vida como factores clave de la felicidad a nivel global.

Si hacemos una comparación entre los modelos LMM y GLMM a través de sus predicciones para el ranking de felicidad de 2025, tal como se presenta en la @tbl-ranking-2025, vemos como la mayoría de resultados coinciden, tanto en posiciones superiores como en posiciones inferiores del ranking; demostrando la robustez del modelo mixto para este tipo de datos, independientemente de la familia de distribución asumida. Sin embargo, para decidir qué modelo es mejor utilizaremos como criterio el coeficiente de determinación R², ya que es una medida que se utiliza precisamente para evaluar la capacidad explicativa de los modelos. Como hemos visto antes, en el caso del modelo mixto lineal (LMM), el R² marginal alcanza un valor de **0.702**, mientras que el R² condicional asciende a **0.932**. Por el contrario, el modelo mixto generalizado (GLMM) presenta únicamente un R² marginal de **0.387**, sin poder estimarse el R² condicional debido a problemas de singularidad. Esta diferencia muestra que el modelo LMM explica una proporción mucho mayor de la variabilidad observada en el Happiness Score, por lo que concluimos que el modelo LMM es notablemente superior al GLMM en términos de capacidad explicativa y ajuste general a los datos.

A partir de los resultados obtenidos en este capítulo, se ha desarrollado una aplicación interactiva en Shiny que permite explorar dinámicamente los modelos mixtos ajustados sobre los datos de felicidad. La aplicación está diseñada para que el usuario pueda seleccionar distintas combinaciones de efectos fijos y aleatorios, y visualizar tanto los coeficientes estimados como las métricas de calidad del modelo (AIC, R² marginal y condicional). Además, en caso de que el modelo generado sea válido, se pueden hacer predicciones personalizadas para el año siguiente, lo que permite observar el comportamiento del modelo bajo distintos escenarios. Esta aplicación refleja de manera interactiva todo el proceso de modelado que se ha ido desarrollando en este capítulo, concediendo al usuario la capacidad de comprobar los diferentes factores que pueden influir en la felicidad y la capacidad de comprender cómo los modelos mixtos se ajustan a datos longitudinales. Dicha aplicación está descrita en el siguiente capítulo.

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, warning=FALSE}
library(readr)
library(readxl)
library(janitor)
library(mice)
library(visdat)
library(outliers)
library(plotly)
library(tidyverse)
library(webshot2)
library(lmtest)      # Para bptest() y dwtest()
library(tseries)     # Para jarque.bera.test()
library(ggfortify)   # Para autoplot() del modelo

```

# Construcción del modelo

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(
  fig.width = 6, 
  fig.height = 4, 
  dev = "png",
  fig.align = "center"
)
theme_set(theme_minimal(base_size = 12))
```


En este capítulo desarrollamos el proceso de construcción de un modelo estadístico para explicar y predecir la percepción de felicidad (Happiness Score) a lo largo del tiempo, utilizando los datos longitudinales disponibles para todos los países entre los años 2015 y 2024. Dado que el análisis de este trabajo se centra en la evolución de la felicidad en el tiempo, consideramos esencial aprovechar toda la información disponible, en lugar de limitar el estudio a una única foto fija (por ejemplo, el año 2024).

El objetivo de este capítulo es construir un modelo que sea estadísticamente sólido y al mismo tiempo interpretable en el contexto de los determinantes sociales, económicos y políticos de la felicidad. Para ello, combinaremos herramientas de la estadística clásica (regresión lineal múltiple) con técnicas específicas para datos longitudinales, incluyendo modelos mixtos que permiten tener en cuenta la estructura jerárquica de los datos (países medidos en diferentes años).

El proceso de modelado se abordará desde dos estrategias complementarias:

- **Top-down**: partimos de un modelo completo que incluye todas las variables relevantes, y vamos eliminando aquellas que no aportan información significativa o que generan problemas como multicolinealidad o sobreajuste.

- **Bottom-up**: comenzamos con un modelo simple con pocas variables y vamos añadiendo progresivamente nuevos predictores, evaluando si su inclusión mejora sustancialmente el ajuste del modelo.

Ambos enfoques nos permiten analizar el trade-off entre complejidad y capacidad explicativa, y encontrar un equilibrio adecuado.

Dado que trabajamos con datos que varían a lo largo del tiempo para cada país, es importante distinguir entre:

- **Variables longitudinales**: cambian con el tiempo (por ejemplo, `gdp`, `support`, `freedom`, `generosity`, `life_exp`, `corruption`).
- **Variables fijas**: son constantes en el tiempo o se utilizan como contexto (por ejemplo, `region`, si se decide mantener como factor).

Además, es importante tener en cuenta la dependencia temporal entre observaciones del mismo país. Este aspecto será considerado al ajustar modelos mixtos con interceptos (y potencialmente pendientes) aleatorios por país.

## Análisis exploratorio y selección inicial de variables

Aunque ya se analizó previamente la estructura de los datos, antes de ajustar cualquier modelo es útil revisar de nuevo las características más relevantes desde una perspectiva predictiva, identificando posibles problemas (como valores faltantes o outliers) y seleccionando las variables que podrían actuar como buenos predictores del happiness_score.

### Estructura del dataset longitudinal

Nuestro conjunto de datos contiene observaciones anuales de múltiples países en el período 2015–2024. Para cada país y año, disponemos de una serie de variables socioeconómicas y de percepción ciudadana. Las variables disponibles son:

- `happiness_score`: puntuación de felicidad (variable respuesta)
- `gdp`: producto interior bruto per cápita
- `support`: percepción de apoyo social
- `life_exp`: esperanza de vida saludable
- `freedom`: libertad para tomar decisiones
- `generosity`: generosidad de la población
- `corruption`: percepción de corrupción en instituciones
- `country`: identificador del país
- `year`: año de la observación
- `regional_indicator`: región a la que pertenece el país

Dado el enfoque longitudinal, usaremos `country` como unidad de agrupación para modelar efectos específicos de cada país a lo largo del tiempo.

### Visualización y evolución temporal de las variables

A continuación, exploramos cómo varían las principales variables predictoras a lo largo del tiempo. Esto nos ayuda a evaluar la estabilidad o variabilidad de cada predictor y su potencial relación con el `happiness_score`.
```{r warning=FALSE, include=FALSE}
# Carga de paquetes 
library(readr)
library(readxl)
library(janitor)
library(mice)
library(visdat)
library(outliers)
library(plotly)
library(tidyverse)
library(webshot2)

# Cargamos los datos 
df_original <- read_delim("world_happiness_combined.csv", delim = ";", show_col_types = FALSE)
# Limpiar nombres de columnas
df_original <- clean_names(df_original)
summary(df_original)
str(df_original)
# Hay algunas variables numérias que están puestas como categóricas
df_original <- df_original %>%
  mutate(
    gdp_per_capita = as.numeric(gsub(",", ".", gdp_per_capita)),
    social_support = as.numeric(gsub(",", ".", social_support)),
    freedom_to_make_life_choices = as.numeric(gsub(",", ".", freedom_to_make_life_choices)),
    generosity = as.numeric(gsub(",", ".", generosity)),
    perceptions_of_corruption = as.numeric(gsub(",", ".", perceptions_of_corruption))
  )
# Verificar que ahora sean numéricas
str(df_original)
# Hay un problema con las comas en el happiness score
df_original$happiness_score <- df_original$happiness_score / 100000
# Datos faltantes
is.na(df_original)
# En la base de datos no hay ningún dato faltante

# Detección de Outliers
boxplot(df_original$happiness_score)
boxplot(df_original$gdp_per_capita)
boxplot(df_original$social_support)  
boxplot(df_original$healthy_life_expectancy)
boxplot(df_original$freedom_to_make_life_choices)
boxplot(df_original$generosity)
boxplot(df_original$perceptions_of_corruption)
# Como podemos apreciar gráficamente, hay algunas variables numéricas en las que puede haber valores atípicos
outliers::grubbs.test(df_original$happiness_score)
outliers::grubbs.test(df_original$gdp_per_capita)
outliers::grubbs.test(df_original$social_support)
outliers::grubbs.test(df_original$healthy_life_expectancy)
outliers::grubbs.test(df_original$freedom_to_make_life_choices)
outliers::grubbs.test(df_original$generosity)
outliers::grubbs.test(df_original$perceptions_of_corruption)
# Como el p-valor es > alpha en todos los test, no tenemos outliers
df_original <- df_original %>%
  rename(
    gdp = gdp_per_capita,
    support = social_support,
    life_exp = healthy_life_expectancy,
    freedom = freedom_to_make_life_choices,
    generosity = generosity,
    corruption = perceptions_of_corruption
  )
```

```{r include=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(stringr)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(htmlwidgets)
## FREEDOM IN THE WORLD
freedom_todos <- read_excel("All_data_FIW_2013-2024 (1).xlsx", sheet = "FIW13-25", skip = 1)
### Las variables que nos pueden llegar a interesar son:
#### Country/Territory (necesitamos el país/territorio)
#### Region (aunque sea muy parecida a la de regional_indicator, nos puede ser de utilidad)
#### c/T (indica si es país o territorio, aunque no se si deberíamos de meternos con el concepto de soberanía)
#### Edition (necesitamos el año)
#### Status (clasifica la libertad del país)
#### PR (derechos políticos) rating y CL (libertades civiles) rating (la otra opción sería elegir PR, CL y Total porque el rating va de 1 a 7)
freedom_final <- freedom_todos %>%
  select(
    `Country/Territory`, # Nombre del país o territorio
    `Region`,            # Región geográfica
    `C/T`,               # Indica si es país (c) o territorio (t)
    `Edition`,           # Año de edición de los datos
    `Status`,            # Clasificación de libertad (Libre, Parcialmente Libre, No Libre)
    `PR rating`,         # Puntuación de derechos políticos (1-7)
    `CL rating`          # Puntuación de libertades civiles (1-7)
  ) %>%
  rename(
    country = `Country/Territory`,
    region = `Region`,
    country_or_territory = `C/T`,
    year = `Edition`,
    status = `Status`,
    political_rights = `PR rating`,
    civil_liberties = `CL rating`
  )
freedom_final <- freedom_final %>%
  filter(year >= 2015 & year <= 2024)
## DEMOCRACY DATA ==> DEMOCRACY AND DICTATORSHIP
library(democracyData)
democracy_data <-
  democracyData::pacl_update |> 
  janitor::clean_names() |> 
  dplyr::select(
    "country_name" = "pacl_update_country",
    "country_code" = "pacl_update_country_isocode",
    "year",
    "regime_category_index" = "dd_regime",
    "regime_category" = "dd_category",
    "is_monarchy" = "monarchy",
    "is_commonwealth" = "commonwealth",
    "monarch_name",
    "monarch_accession_year" = "monarch_accession",
    "monarch_birthyear",
    "is_female_monarch" = "female_monarch",
    "is_democracy" = "democracy",
    "is_presidential" = "presidential",
    "president_name",
    "president_accesion_year" = "president_accesion",
    "president_birthyear",
    "is_interim_phase" = "interim_phase",
    "is_female_president" = "female_president",
    "is_colony" = "colony",
    "colony_of",
    "colony_administrated_by",
    "is_communist" = "communist",
    "has_regime_change_lag" = "regime_change_lag",
    "spatial_democracy",
    "parliament_chambers" = "no_of_chambers_in_parliament",
    "has_proportional_voting" = "proportional_voting",
    "election_system",
    "lower_house_members" = "no_of_members_in_lower_house",
    "upper_house_members" = "no_of_members_in_upper_house",
    "third_house_members" = "no_of_members_in_third_house",
    "has_new_constitution" = "new_constitution",
    "has_full_suffrage" = "fullsuffrage",
    "suffrage_restriction",
    "electoral_category_index" = "electoral",
    "spatial_electoral",
    "has_alternation" = "alternation",
    "is_multiparty" = "multiparty",
    "has_free_and_fair_election" = "free_and_fair_election",
    "parliamentary_election_year",
    "election_month" = "election_month_year",
    "has_postponed_election" = "postponed_election"
  ) |>
  dplyr::mutate(
    election_month = dplyr::na_if(.data$election_month, "?")
  ) |> 
  tidyr::separate_wider_regex(
    "election_month",
    patterns = c(
      election_month = "\\D+",
      election_year = "\\d{4}$"
    ),
    too_few = "align_start"
  ) |> 
  dplyr::mutate(
    electoral_category = dplyr::case_match(
      .data$electoral_category_index,
      0 ~ "no elections",
      1 ~ "single-party elections",
      2 ~ "non-democratic multi-party elections",
      3 ~ "democratic elections"
    ),
    .after = "electoral_category_index"
  ) |> 
  dplyr::mutate(
    election_month = stringr::str_squish(.data$election_month),
    dplyr::across(
      c(
        tidyselect::ends_with("_index"),
        tidyselect::contains("year"),
        tidyselect::ends_with("_members"),
        "parliament_chambers"
      ),
      as.integer
    ),
    dplyr::across(
      c(
        tidyselect::starts_with("is_"),
        tidyselect::starts_with("has_")
      ),
      as.logical
    )
  )
### Las variables que nos pueden llegar a interesar son:
#### country_name (necesitamos el país/territorio)
#### year (año)
#### regime_category (Parliamentary democracies, Mixed democracies (with weak presidents), Presidential democracies, Civilian autocracies, Military dictatorships, Royal dictatorships)
#### is_monarchy (es monarquía o no)
#### is_democracia (es democracia o no)
#### is_presidential (es presidencial o no)
#### is_colony (es colonia o no)
#### is_communist (es comunista o no)
#### spatial_democracy (como de democráticos son sus países vecinos) 
#### has_full_suffrage (tiene sufragio universal o no)
#### electoral_category (No elections, Single-party elections, non-democratic multi-party elections, democratic elections)
#### spatial_electoral (cómo son las elecciones en sus países vecinos)
#### has_free_and_fair_election (tienen elecciones justas o no)
#### has_alternation (cambian de gobierno o no)
democracy_final <- democracy_data %>%
  select(
    country_name, 
    year, 
    regime_category, 
    is_monarchy, 
    is_democracy, 
    is_presidential, 
    is_colony, 
    is_communist, 
    spatial_democracy, 
    has_full_suffrage, 
    electoral_category, 
    spatial_electoral, 
    has_free_and_fair_election, 
    has_alternation
  ) %>%
  rename(
    monarchy = is_monarchy,
    democracy = is_democracy,
    presidential = is_presidential,
    colony = is_colony,
    communist = is_communist,
    sp_democracy = spatial_democracy,
    suffrage = has_full_suffrage,
    sp_electoral = spatial_electoral,
    fair_election = has_free_and_fair_election,
    alternation = has_alternation
  )
democracy_final <- democracy_final %>%
  filter(year >= 2015 & year <= 2024)
## UNIÓN DE LOS DATASETS
colnames(df_original)
colnames(democracy_final)
colnames(freedom_final)
# Renombrar la columna 'country_name' en democracy_final para que coincida con df_original
democracy_final <- democracy_final %>%
  rename(country = country_name)
# Ver los países en cada dataset para ver si hay alguna diferencia en la nomenclatura
unique(df_original$country)
unique(democracy_final$country)
unique(freedom_final$country)

setdiff(df_original$country, democracy_final$country)
setdiff(democracy_final$country, df_original$country)
setdiff(df_original$country, freedom_final$country)
setdiff(freedom_final$country, df_original$country)
# Corrección de nombres 
df_original <- df_original %>%
  mutate(country = case_when(
    country == "Trinidad & Tobago" ~ "Trinidad and Tobago",
    country == "Somaliland region" ~ "Somaliland",
    country == "Macedonia" ~ "North Macedonia",
    country == "Palestinian Territories" ~ "State of Palestine",
    country == "Congo" ~ "Congo (Kinshasa)",
    country == "Taiwan Province of China" ~ "Taiwan",
    country == "Hong Kong S.A.R. of China" ~ "Hong Kong",
    country == "Czechia" ~ "Czech Republic",
    country == "Turkiye" ~ "Turkey",
    country == "Argelia" ~ "Algeria",
    country == "Eswatini" ~ "Swaziland",
    TRUE ~ country
  ))
democracy_final <- democracy_final %>%
  mutate(country = case_when(
    country == "Slovak Republic" ~ "Slovakia",
    country == "Korea, Republic of" ~ "South Korea",
    country == "Trinidad &Tobago" ~ "Trinidad and Tobago",
    country == "Congo, Dem. Rep." ~ "Congo (Kinshasa)",
    country == "Congo, Republic of" ~ "Congo (Brazzaville)",
    country == "Gambia, The" ~ "Gambia",
    country == "Côte d`Ivoire" ~ "Ivory Coast",
    TRUE ~ country
  ))
freedom_final <- freedom_final %>%
  mutate(country = case_when(
    country == "Northern Cyprus" ~ "North Cyprus",
    country == "The Gambia" ~ "Gambia",
    country == "Cote d'Ivoire" ~ "Ivory Coast",
    country == "Eswatini" ~ "Swaziland",
    TRUE ~ country
  ))

# PRIMER DATAFRAME: df_completo (2015-2020, con todas las variables)
df_completo <- df_original %>%
  left_join(democracy_final, by = c("country", "year")) %>%
  left_join(freedom_final, by = c("country", "year")) %>%
  filter(year >= 2015 & year <= 2020)  # Filtrar solo hasta 2020

# SEGUNDO DATAFRAME: df_sin_democracia (2015-2024, sin democracy_final)
df_sin_democracia <- df_original %>%
  left_join(freedom_final, by = c("country", "year")) %>%
  filter(year >= 2015 & year <= 2024)  # Mantener toda la información de felicidad y libertad

summary(df_completo)
summary(df_sin_democracia)

na_presence_completo <- df_completo %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))

na_presence_sin_democracia <- df_sin_democracia %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))

# OPCIÓN 1: ELIMINAR LOS NA
df_completo_sin_na <- df_completo %>% drop_na()
df_sin_democracia_sin_na <- df_sin_democracia %>% drop_na()

# OPCIÓN 2: SUSTITUIR LOS NA
# VARIABLES NUMÉRICAS
df_completo_numeric <- df_completo %>%
  select_if(is.numeric)
df_sin_democracia_numeric <- df_sin_democracia %>%
  select_if(is.numeric)
imputacion_completo <- mice(df_completo_numeric, method = "pmm", m = 5, maxit = 50, seed = 123)
df_completo_pmm <- complete(imputacion_completo)
imputacion_sin_democracia <- mice(df_sin_democracia_numeric, method = "pmm", m = 5, maxit = 50, seed = 123)
df_sin_democracia_pmm <- complete(imputacion_sin_democracia)
df_completo_pmm <- bind_cols(df_completo %>% select(-colnames(df_completo_numeric)), df_completo_pmm)
df_sin_democracia_pmm <- bind_cols(df_sin_democracia %>% select(-colnames(df_sin_democracia_numeric)), df_sin_democracia_pmm)
# VARIABLES CATEGÓRICAS
md.pattern(df_completo_pmm)
vis_miss(df_completo_pmm, sort_miss=TRUE)
na_presence_completo_pmm <- df_completo_pmm %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))
df_completo_pmm <- df_completo_pmm %>%
  mutate(
    regional_indicator = case_when(
      country == "Greece" ~ "Western Europe",
      country == "Cyprus" ~ "Western Europe",
      country == "Gambia" ~ "Sub-Saharan Africa",
      TRUE ~ regional_indicator
    ),
    colony = ifelse(country == "Libya", FALSE, colony)
  ) %>%
  filter(!country %in% c("North Cyprus", "Kosovo", "Somaliland", "State of Palestine"))


md.pattern(df_sin_democracia_pmm)
vis_miss(df_sin_democracia_pmm, sort_miss=TRUE)
na_presence_sin_democracia_pmm <- df_sin_democracia_pmm %>%
  summarise(across(everything(), ~ any(is.na(.)), .names = "NA_{.col}"))
df_sin_democracia_pmm <- df_sin_democracia_pmm %>%
  mutate(
    regional_indicator = case_when(
      country == "Greece" ~ "Western Europe",
      country == "Cyprus" ~ "Western Europe",
      country == "Gambia" ~ "Sub-Saharan Africa",
      TRUE ~ regional_indicator
    ),
  ) %>%
  filter(!country %in% c("State of Palestine"))
# Eliminar territorios
df_sin_democracia_sin_na <- df_sin_democracia_sin_na %>%
  filter(tolower(country_or_territory) == "c") %>%  # Solo países

  # Eliminar la variable 'country_or_territory'
  select(-country_or_territory)
```


```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-variables-informe
#| echo: false
#| warning: false
#| fig-cap: "Evolución temporal de la esperanza de vida"
library(ggplot2)
library(dplyr)
library(tidyr)

# Agrupamos por año y sacamos medias globales
df_temporal <- df_sin_democracia_sin_na %>%
  group_by(year) %>%
  summarise(across(c(happiness_score, gdp, support, life_exp, corruption, freedom, generosity), ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(-year, names_to = "variable", values_to = "media")

# Convertimos año a integer para que no aparezca con decimales
df_temporal$year <- as.integer(df_temporal$year)

# GRÁFICO 1: Solo life_exp
df_temporal %>% 
  filter(variable == "life_exp") %>%
  ggplot(aes(x = year, y = media, color = variable)) +
  geom_line(size = 1) +
  labs(title = "Evolución temporal de la esperanza de vida",
       x = "Año", y = "Media mundial") +
  theme_minimal() +
  scale_x_continuous(breaks = unique(df_temporal$year))

```

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-variables-informe2
#| echo: false
#| warning: false
#| fig-cap: "Evolución temporal de la percepción de corrupción, libertad, generosidad y apoyo social"
# GRÁFICO 2: corruption, freedom, generosity y support
df_temporal %>% 
  filter(variable %in% c("corruption", "freedom", "generosity", "support")) %>%
  ggplot(aes(x = year, y = media, color = variable)) +
  geom_line(size = 1) +
  labs(title = "Evolución de variables sociales",
       x = "Año", y = "Media mundial") +
  theme_minimal() +
  scale_x_continuous(breaks = unique(df_temporal$year))

```

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-variables-informe3
#| echo: false
#| warning: false
#| fig-cap: "Evolución temporal del PIB y la felicidad"
# GRÁFICO 3: gdp y happiness_score
df_temporal %>% 
  filter(variable %in% c("gdp", "happiness_score")) %>%
  ggplot(aes(x = year, y = media, color = variable)) +
  geom_line(size = 1) +
  labs(title = "Evolución del PIB y la felicidad",
       x = "Año", y = "Media mundial") +
  theme_minimal() +
  scale_x_continuous(breaks = unique(df_temporal$year))

```

Observando la @fig-variables-informe, vemos que la esperanza de vida muestra una tendencia general al alza, con ciertas oscilaciones intermedias que podrían estar asociadas a eventos sanitarios globales como la pandemia de COVID-19. El incremento observado en 2022 es particularmente destacado y podría requerir un análisis más desagregado por región. Las variables sociales de la @fig-variables-informe2 presentan comportamientos diferenciados. La percepción de corrupción (`corruption`) muestra variaciones abruptas que podrían reflejar problemas de medición o eventos políticos clave. La libertad de tomar decisiones (`freedom`) y el apoyo social (`support`) se mantienen relativamente estables, mientras que la generosidad (`generosity`) parece haber aumentado gradualmente en los últimos años. La evolución del PIB (`gdp`) en la @fig-variables-informe3 muestra un aumento importante entre 2020 y 2022, que puede deberse a efectos de recuperación tras la pandemia. El `happiness_score` permanece mucho más estable a lo largo del tiempo, lo que sugiere que el crecimiento económico no se traduce automáticamente en un incremento proporcional de la felicidad percibida. Sin embargo, también podría interpretarse como un efecto con retardo, en el que los beneficios del aumento del PIB se reflejan en el bienestar subjetivo con cierto desfase temporal.

### Matriz de correlaciones

Antes de ajustar ningún modelo, es útil examinar la correlación entre las variables explicativas y la variable objetivo happiness_score. Esto nos permitirá identificar posibles relaciones lineales, evaluar redundancias y tomar decisiones informadas sobre qué variables incluir inicialmente en el modelo.

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-matriz
#| echo: false
#| warning: false
#| fig-cap: "Matriz de correlaciones de las variables de nuestra base de datos"
# Cargar librerías necesarias
library(corrplot)
library(GGally)
library(dplyr)

# Seleccionamos las variables de interés para el modelo
df_modelo <- df_sin_democracia_sin_na %>%
  select(happiness_score, gdp, life_exp, support, freedom, generosity, corruption)

# Calculamos la matriz de correlaciones de Pearson
cor_matrix <- cor(df_modelo, use = "complete.obs", method = "pearson")

# Visualizamos la matriz de correlaciones
corrplot(cor_matrix, method = "color", type = "upper",
         addCoef.col = "black", number.cex = 0.7, tl.cex = 0.8, tl.col = "black",
         col = colorRampPalette(c("red", "white", "blue"))(200))


```

Como se puede observar en la @fig-matriz, las correlaciones más fuertes con happiness_score corresponden a:

- support (0.75): el apoyo social es la variable que más se relaciona con la felicidad percibida.

- life_exp (0.67) y gdp (0.63): muestran relaciones importantes, lo que refleja la relevancia del bienestar económico y la salud.

- freedom (0.59) también presenta una relación moderada.

En cambio, variables como generosity (0.10) y corruption (0.07) muestran una relación muy débil con la felicidad, lo que hace cuestionable su relevancia explicativa. Las correlaciones entre predictores no son excesivamente altas (ninguna supera 0.8), por lo que, en principio, no se anticipan grandes problemas de multicolinealidad. Aun así, esto se verificará más adelante con el cálculo de los VIF (Variance Inflation Factor).

Este análisis justifica incluir support, life_exp, gdp y freedom en una primera versión del modelo, aunque se explorarán también modelos más parciales para comparar rendimiento y parsimonia.

## Criterios de selección del modelo

Al construir un modelo estadístico, es común que existan múltiples combinaciones posibles de predictores. Para elegir la especificación más adecuada, se utilizan criterios que balancean dos aspectos fundamentales: el ajuste al conjunto de datos (qué tan bien predice el modelo los datos observados), y la complejidad del modelo (cuántos parámetros se incluyen). Dos de los criterios más utilizados para este propósito son el Akaike Information Criterion (AIC) y el Bayesian Information Criterion (BIC).

AIC penaliza la complejidad del modelo y busca minimizar la pérdida de información. Se calcula como:
Dos de los criterios más utilizados para este propósito son el Akaike Information Criterion (AIC) y el Bayesian Information Criterion (BIC).

AIC penaliza la complejidad del modelo y busca minimizar la pérdida de información. Se calcula como:
$$
\text{AIC} = -2 \cdot \log(\hat{L}) + 2k
$$
donde $\hat{L}$ es la verosimilitud máxima del modelo y k el número de parámetros.

BIC penaliza más fuertemente los modelos complejos (dependiendo del tamaño de muestra n):
$$
\text{BIC} = -2 \cdot \log(\hat{L}) + k \cdot \log(n)
$$
Un AIC o BIC más bajo indica un mejor modelo, pero el AIC tiende a seleccionar modelos más complejos (es más permisivo); mientras que el BIC favorece modelos más parsimoniosos (penaliza más la complejidad). Ambos criterios se pueden usar para comparar modelos con los mismos datos y la misma variable respuesta.

## Modelado clásico

Como punto de partida, construimos un modelo clásico de regresión lineal múltiple para explicar el happiness_score a partir de variables como gdp, life_exp, support, freedom, generosity y corruption. Para explorar la mejor combinación de predictores, aplicamos dos estrategias de selección de variables:

```{r message=FALSE, warning=FALSE, include=FALSE}
# Ajuste del modelo completo
modelo_completo <- lm(happiness_score ~ gdp + life_exp + support + freedom + generosity + corruption, data = df_sin_democracia_sin_na)

summary(modelo_completo)

```

### Estrategia top-down (backward elimination)

Usamos el criterio AIC y BIC para eliminar aquellas variables cuya eliminación mejora la simplicidad del modelo sin sacrificar capacidad predictiva.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Selección con AIC
modelo_step_aic <- step(modelo_completo, direction = "backward", k = 2)

# Selección con BIC
modelo_step_bic <- step(modelo_completo, direction = "backward", k = log(nrow(df_sin_democracia_sin_na)))

```

En la selección según AIC, el modelo presenta un AIC final de -1590.3, donde la variable generosity fue descartada por no aportar mejora significativa al modelo, lo cual concuerda con su baja correlación con la variable objetivo observada anteriormente. Por su parte, el BIC penaliza más severamente los modelos complejos, favoreciendo modelos más parsimoniosos. En este caso, el modelo óptimo según BIC también descarta generosity, y produce exactamente la misma especificación final que el modelo por AIC. Esto refuerza la robustez del modelo seleccionado, al coincidir ambos criterios a pesar de su diferencia en la penalización por número de parámetros.

### Estrategia bottom-up (forward selection)

También exploramos una estrategia bottom-up (selección hacia adelante), que parte de un modelo nulo y añade variables una a una en función de la mejora del AIC. Esta estrategia permite comprobar si existe alguna combinación alternativa de predictores que produzca un modelo competitivo o incluso mejor al obtenido por eliminación hacia atrás.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Modelo nulo y completo
modelo_nulo <- lm(happiness_score ~ 1, data = df_sin_democracia_sin_na)
modelo_completo <- lm(happiness_score ~ gdp + life_exp + support + freedom + generosity + corruption, data = df_sin_democracia_sin_na)

# Forward selection
modelo_step_forward <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_completo), direction = "forward")

```

En este caso, el procedimiento fue incorporando progresivamente variables hasta alcanzar el modelo completo, es decir, con todos los predictores. Este resultado contrasta con el modelo obtenido por backward elimination, en el que algunas variables eran descartadas. Esta diferencia refleja que los criterios de selección pueden llevar a soluciones distintas según el punto de partida.

En base a los resultados anteriores, el modelo final que utilizaremos es: happiness_score ~ gdp + life_exp + support + freedom + corruption. Este modelo muestra un equilibrio adecuado entre capacidad predictiva y parsimonia. Como veremos en la siguiente sección, se procederá ahora a evaluar el ajuste del modelo, su interpretación y su validación diagnóstica.

### Diagnóstico y validación final del modelo

Una vez seleccionado el modelo de regresión múltiple más adecuado según los criterios AIC y BIC, es fundamental verificar si cumple con las hipótesis necesarias para garantizar su validez estadística. Estas hipótesis incluyen:

- Normalidad de los residuos.

- Media cero de los residuos.

- Homoscedasticidad (varianza constante de los errores).

- Independencia de los errores.

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-modelo-clasico
#| echo: false
#| warning: false
#| fig-cap: "Gráficas para la validación del modelo clásico"
modelo_final <- lm(happiness_score ~ support + life_exp + freedom + gdp + corruption,
                   data = df_sin_democracia_sin_na)
autoplot(modelo_final, which = 1:4)

```


#### Normalidad de los residuos

Se aplica el test de Jarque-Bera para evaluar si los residuos del modelo siguen una distribución normal. El resultado indica un p-valor muy bajo, lo que nos lleva a rechazar la hipótesis de normalidad.

```{r message=FALSE, warning=FALSE, include=FALSE}
jarque.bera.test(modelo_final$residuals)
```

El p-valor obtenido es extremadamente bajo (p-value = 2.195e-10), lo que indica que los residuos no siguen una distribución normal. Esto también se confirma visualmente en el gráfico Q-Q de la @fig-modelo-clasico, donde los residuos llega un momento en el que se desvían de la línea teórica.

#### Media cero

Calculamos la media de los residuos para verificar si se aproxima a cero, como requiere el modelo. En este caso, se cumple adecuadamente:

```{r message=FALSE, warning=FALSE, include=FALSE}
mean(modelo_final$residuals)
```

Si observamos la gráfica Residuals vs Fitted en la @fig-modelo-clasico, podríamos decir que los residuos están uniformemente dispersos alrededor del eje de abscisas, por lo que se cumple la condición de que los residuos tienen media cero.

#### Homoscedasticidad

Se aplica la prueba de Breusch-Pagan para comprobar si la varianza de los errores es constante. El resultado del test devuelve un p-valor bajo, lo que sugiere la existencia de heterocedasticidad.

```{r message=FALSE, warning=FALSE, include=FALSE}
bptest(modelo_final, studentize = FALSE)

```

El gráfico de residuos frente a los valores ajustados de la @fig-modelo-clasico también muestra un patrón creciente, indicio visual de heterocedasticidad. El test devuelve un p-valor < 2.2e-16, por lo que rechazamos la hipótesis nula de homocedasticidad. Esto indica que hay heterocedasticidad en los residuos, es decir, su varianza no es constante.

#### No correlación de los errores

Mediante el test de Durbin-Watson, se verifica que no exista autocorrelación en los residuos. En este caso, el p-valor es suficientemente alto como para no rechazar la hipótesis nula, por lo que la independencia de los errores se mantiene.

```{r message=FALSE, warning=FALSE, include=FALSE}
dwtest(modelo_final)

```

Con un estadístico de Durbin-Watson de 1.4461 y un p-valor < 2.2e-16, se concluye que existe autocorrelación positiva entre los residuos.

#### Conclusión del diagnóstico

Estos incumplimientos sugieren que el modelo, aunque aparentemente ajustado, no es estadísticamente válido en un contexto longitudinal. Específicamente, ignora la dependencia entre observaciones del mismo país a lo largo del tiempo, lo que puede sesgar los resultados.

La inadecuación del modelo clásico justifica el uso de enfoques más robustos, capaces de incorporar la estructura jerárquica de los datos. En particular, los modelos lineales mixtos (LMM) permiten modelar efectos aleatorios por país, capturar la correlación intrínseca entre medidas repetidas y mejorar la validez estadística y la interpretación de los resultados. En la siguiente sección abordamos su aplicación utilizando la función lmer() del paquete lme4.

## Modelos Lineales Mixtos (LMM)

En el análisis clásico mediante regresión lineal múltiple, se asumía que las observaciones eran independientes entre sí. Sin embargo, en nuestro caso trabajamos con datos longitudinales, es decir, con observaciones repetidas a lo largo del tiempo para los mismos países. Esto introduce una dependencia entre observaciones dentro del mismo país, que los modelos clásicos no pueden capturar adecuadamente.

Para abordar esta limitación, recurrimos a los modelos lineales mixtos (LMM). Estos modelos permiten combinar efectos fijos, que capturan el efecto promedio de los predictores sobre la variable respuesta en toda la población; y efectos aleatorios, que permiten modelar la variabilidad específica entre países, incorporando interceptos (y potencialmente pendientes) distintos para cada uno. De esta forma podemos capturar la estructura jerárquica de los datos, reconociendo que cada país puede tener un nivel base de felicidad distinto (intercepto propio), mientras que los efectos de las variables predictoras son comunes a todos los países. En nuestro modelo, se consideran efectos fijos aquellas variables explicativas cuyo efecto queremos estimar de forma generalizable para toda la población (en este caso, todos los países y años). Estas variables incluyen gdp, support, freedom, life_exp, corruption y las variables políticas (is_democracy, regime_category, etc.). Se introduce un efecto aleatorio por país (intercepto aleatorio), porque cada país tiene un nivel base distinto de felicidad no explicado por las variables fijas, hay dependencia entre observaciones del mismo país en distintos años, y no nos interesa estimar el efecto específico de cada país, sino tener en cuenta la variabilidad entre ellos. En nuestro caso, el modelo lineal mixto adoptado es el siguiente:

\begin{align*}
\text{happiness}_{ij} &= \beta_0 
+ \beta_1 \cdot \text{support}_{ij} 
+ \beta_2 \cdot \text{lifeexp}_{ij} 
+ \beta_3 \cdot \text{freedom}_{ij} \\
&\quad + \beta_4 \cdot \text{gdp}_{ij} 
+ \beta_5 \cdot \text{corruption}_{ij} 
+ \beta_6 \cdot \text{generosity}_{ij} 
+ \beta_7 \cdot \text{year}_{ij} \\
&\quad + u_{0j} + \varepsilon_{ij}
\end{align*}


donde:

- $\text{happiness}_{ij}$ es la puntuación de felicidad observada para el país $j$ en el año $i$.
- `support`, `life_exp`, `freedom`, `gdp`, `corruption`, `generosity` y `year` se incluyen como efectos fijos, comunes a todos los países.
- $\beta_0, \ldots, \beta_6$ son los coeficientes de estos efectos fijos.
- $u_{0j} \sim \mathcal{N}(0, \sigma^2_u)$ representa un efecto aleatorio de intercepto para el país $j$, permitiendo variación en la felicidad media entre países.
- $\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2)$ es el término de error individual, independiente e idénticamente distribuido.

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(lme4)
modelo_mixto <- lmer(happiness_score ~ support + life_exp + freedom + gdp + corruption + generosity + year + (1 | country),
                     data = df_sin_democracia_sin_na)
summary(modelo_mixto)

```

Si nos fijamos en los efectos aleatorios, la desviación estándar del intercepto por país es de 0.7631, lo que refleja una importante variabilidad estructural entre países; mientras que el término residual tiene desviación estándar 0.2992, menor que la del intercepto aleatorio, lo que refuerza la utilidad del modelo mixto. Analizando los efectos fijos, vemos como todas las variables menos corruption y year son significativas; pero las variables más destacadas son support, generosity y freedom ya que son aquellas que, debido al alto valor de sus coeficientes estimados, mayor impacto tienen en el modelo.

Antes de proceder al diagnóstico exhaustivo del modelo propuesto, es importante evaluar si esta especificación es la más adecuada para los datos. Para ello, se comparan múltiples modelos candidatos que varían en los predictores incluidos, utilizando el criterio de información de Akaike (AIC), previamente descrito. En el caso de modelos mixtos, existe una distinción importante entre dos métodos de estimación:

- REML (Restricted Maximum Likelihood): se recomienda cuando el objetivo es obtener estimaciones precisas de la varianza de los efectos aleatorios, manteniendo fija la estructura de efectos fijos. No se debe usar REML para comparar modelos con diferentes predictores fijos.

- ML (Maximum Likelihood): se utiliza para comparar modelos que difieren en los efectos fijos (como sucede en selección de variables), ya que estima la verosimilitud sin condicionar por los efectos fijos.

Por este motivo, para aplicar procedimientos de selección, reajustamos el modelo mixto utilizando ML, y comparamos los AIC de cada especificación candidata. Para identificar el modelo que mejor equilibra capacidad explicativa y simplicidad, utilizamos la función dredge() del paquete MuMIn. Esta herramienta realiza una búsqueda exhaustiva de modelos posibles a partir de un modelo base, generando todas las combinaciones de predictores (con y sin interacción si se desea), y calcula para cada uno de ellos métricas como el AIC, AICc o BIC. El objetivo es seleccionar el modelo que tenga el menor valor de AICc, lo que indica el mejor compromiso entre ajuste y complejidad.

El funcionamiento de dredge() parte del modelo saturado (especificado con todos los predictores que se desean considerar) y construye automáticamente una tabla con los modelos anidados posibles (es decir, con subconjuntos de predictores), ordenados según el criterio de información elegido. Así, permite explorar sistemáticamente múltiples especificaciones del modelo sin necesidad de construir manualmente cada combinación.

Es importante aclarar que dredge() no soluciona directamente los problemas de incumplimiento de supuestos como la normalidad o la homocedasticidad. Sin embargo, al generar modelos más parsimoniosos y mejor ajustados a los datos, puede contribuir a reducir problemas asociados al sobreajuste, la multicolinealidad o la inclusión de predictores irrelevantes, que a menudo empeoran los diagnósticos. Además, al evaluar múltiples combinaciones, permite identificar modelos que además de tener mejor ajuste según el AIC, muestran un comportamiento más estable en los residuos y una estructura más interpretable. Es decir, no arregla los residuos por sí sola, pero ayuda a elegir modelos más adecuados que podrían presentar mejores propiedades estadísticas.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Cargar librerías necesarias
library(lme4)
library(MuMIn)

# Reajustamos el modelo de partida con método ML (obligatorio para comparar modelos)
modelo_mixto_ml <- lmer(
  happiness_score ~ support + life_exp + freedom + gdp + corruption + generosity + year + (1 | country),
  data = df_sin_democracia_sin_na,
  REML = FALSE,
  na.action = na.fail  # Esto es lo que faltaba
)

# Aplicar selección por AIC
modelo_optimo <- dredge(modelo_mixto_ml, trace = FALSE)

# Seleccionar el modelo con menor AIC
modelo_seleccionado <- get.models(modelo_optimo, 1)[[1]]
summary(modelo_seleccionado)

```

El mejor modelo identificado por dredge es aquel con el menor AICc (1288.7), y tiene un peso relativo de 0.284, siendo el más probable entre todos los considerados. El modelo resultante coincide exactamente con el modelo planteado anteriormente, lo cual valida empíricamente la selección inicial de predictores; por lo que no hay ninguna variable prescindible según el criterio de información.

Para evaluar la calidad del modelo, utilizaremos las siguientes medidas: el R² marginal, que representa la proporción de varianza explicada por los efectos fijos, y el R² condicional, que representa proporción de varianza explicada por todo el modelo (fijos + aleatorios).

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(performance)
r2(modelo_seleccionado)
```

Evaluando el modelo, vemos que este resultado refuerza la idea de que la variabilidad entre países es muy importante para explicar la felicidad, y que ignorarla (como hacía el modelo clásico) deja gran parte de la variabilidad sin explicar. Mientras que solo un 22.6% de la variabilidad de la felicidad se explica por los predictores fijos, vemos cómo el 89.6% de la variabilidad se explica cuando se incluye el país como efecto aleatorio y se tiene en cuenta la diferencia entre países. Esto sugiere que el país tiene un peso enorme en la predicción de la felicidad, ya que, incluso controlando por PIB, salud, apoyo social, etc., hay factores estructurales o culturales no capturados en las variables que hacen que los países tengan niveles de felicidad muy distintos. En definitiva, el modelo mixto es mucho más adecuado porque capta esta variabilidad intrínseca entre países que el modelo clásico no podía capturar.

Como en cualquier modelo estadístico, es esencial verificar que las suposiciones sobre los residuos se cumplen también en el contexto de modelos mixtos. En particular, se evaluó la normalidad de los residuos, la homocedasticidad (varianza constante de los errores), y la ausencia de patrones sistemáticos entre residuos y valores ajustados. Para ello, se utilizan gráficos diagnósticos similares a los del modelo clásico, pero adaptados a la estructura jerárquica de los datos. 

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-modelo-bueno
#| echo: false
#| warning: false
#| fig-cap: "Gráficas para la validación del Modelo Lineal Mixto"
library(DHARMa)
library(sjPlot)
library(glmmTMB)
# Visualización rápida
plot_model(modelo_seleccionado, type = "diag")

# Diagnóstico más riguroso
sim_res <- simulateResiduals(fittedModel = modelo_seleccionado)
plot(sim_res)
testResiduals(sim_res)
```

### Normalidad

El gráfico QQ-plot de los residuos muestra una leve pero clara desviación de la diagonal teórica, especialmente en las colas, indicando una ligera asimetría y la posible presencia de valores extremos. Esta percepción se confirma al observar la curva de densidad: aunque la distribución de los residuos es aproximadamente simétrica y centrada en cero, se detecta una mayor concentración en el centro y colas algo más pesadas que las de una distribución normal, lo que apunta a una ligera leptocurtosis.

Los resultados del test de Kolmogorov-Smirnov aplicado a los residuos simulados mediante DHARMa respaldan esta observación. Con un p-valor de 0.0008201, se rechaza la hipótesis nula de normalidad, lo cual confirma estadísticamente la desviación de los residuos respecto a una distribución normal.

Respecto a los efectos aleatorios del modelo, el gráfico QQ-plot de los interceptos aleatorios por país muestra un ajuste bastante bueno a la línea diagonal, con pequeñas desviaciones tolerables en los extremos. Esto sugiere que, a pesar de la no normalidad de los residuos individuales, los efectos aleatorios se distribuyen aproximadamente de forma normal.

### Homocedasticidad

El gráfico de dispersión de residuos frente a valores ajustados no muestra un patrón estructurado ni un aumento sistemático de la varianza, lo que es un indicio favorable para el cumplimiento del supuesto de homocedasticidad. Esta conclusión es reforzada por el test de dispersión de DHARMa, que arroja un p-valor de 0.88. Así, no se puede rechazar la hipótesis nula de varianza constante, confirmando que el modelo presenta homocedasticidad.

### Outliers y estructura de los residuos

El test exacto de binomial de DHARMa señala la presencia de 4 observaciones atípicas (outliers) en una muestra total de 1474, lo que representa una proporción inferior al 0.3%. Sin embargo, esta cantidad, aunque baja, es estadísticamente significativa según el p-valor obtenido (p = 0.01795), lo que indica que la proporción de outliers es ligeramente superior a la esperada por azar.

Por otro lado, el gráfico de residuos simulados frente a predichos evidencia ciertas desviaciones sistemáticas en los cuantiles, con patrones en forma de “S” en los límites superior e inferior. Esto sugiere que el modelo podría no capturar completamente alguna estructura presente en los datos, lo que debería interpretarse con precaución.

### Conclusión del diagnóstico

En conjunto, el modelo mixto ajustado presenta un comportamiento robusto en lo relativo a la homocedasticidad y a la distribución de los efectos aleatorios, y los outliers detectados son escasos y con un impacto potencialmente limitado. No obstante, persisten desviaciones moderadas respecto al supuesto de normalidad en los residuos y ciertos indicios de estructura no explicada en los cuantiles extremos.

Estas irregularidades no invalidan el modelo como herramienta de análisis, pero sí aconsejan una interpretación prudente de sus resultados, especialmente en relación con inferencias que dependan estrictamente de los supuestos clásicos del modelo lineal. En suma, el modelo resulta aceptable para los fines analíticos del estudio, aunque podría beneficiarse de futuras revisiones o mejoras (por ejemplo, modelos con términos no lineales o efectos aleatorios más complejos) si se desea perfeccionar su ajuste.

### Interpretación de coeficientes

En la tabla de efectos fijos, los coeficientes estimados (Estimate) representan el cambio esperado en la puntuación de felicidad (happiness_score) ante un incremento de una unidad en cada variable independiente, manteniendo constantes las demás y considerando el efecto aleatorio del país. A continuación, se interpretan individualmente los efectos más destacados:

- support (β = 0.783): este coeficiente indica que, manteniendo el resto de variables constantes, un aumento de una unidad en el nivel de apoyo social se asocia con un incremento de 0.783 puntos en el índice de felicidad. Es uno de los predictores más significativos del modelo (t = 9.58), con un fuerte impacto positivo.

- freedom (β = 1.180): también tiene un efecto notable sobre la felicidad. A igualdad de condiciones, un país con un punto más de libertad percibida incrementaría su puntuación de felicidad en 1.18 puntos, siendo la variable más influyente del modelo según su coeficiente y su t-valor (t = 11.98).

- generosity (β = 0.351): este predictor también es estadísticamente significativo (t = 2.68) y sugiere que una mayor generosidad percibida está positivamente relacionada con el bienestar subjetivo.

- life_exp (β = 0.0106): aunque el coeficiente es pequeño, la variable resulta estadísticamente significativa (t = 4.30), lo que indica que una mayor esperanza de vida contribuye al incremento del bienestar.

- gdp (β = 0.0125): presenta un efecto positivo y significativo (t = 2.31), aunque de menor magnitud, confirmando que el nivel de riqueza del país también influye, aunque en menor medida.

- corruption (β = 0.0486): no alcanza significancia estadística clara (t = 1.63), por lo que su efecto debe interpretarse con cautela.

- year (β = –0.0059): su coeficiente negativo y no significativo (t = –1.69) indica una ligera tendencia decreciente en el índice de felicidad a lo largo del tiempo, aunque sin evidencia estadística suficiente para afirmarlo con firmeza.

## Selección del mejor modelo

Aunque el modelo mixto planteado inicialmente presenta un buen ajuste estadístico y explicativo, los diagnósticos revelan que no cumple completamente los supuestos teóricos fundamentales. En particular, se observa una ligera desviación de la normalidad de los residuos y una proporción de outliers ligeramente superior a la esperada por azar. Estas violaciones comprometen su idoneidad para realizar predicciones fiables.

Por este motivo, es necesario buscar un modelo alternativo que no solo tenga un buen ajuste según el criterio de información de Akaike (AIC), sino que además cumpla los supuestos fundamentales del modelo lineal mixto, entre ellos: normalidad de residuos, homocedasticidad, y baja proporción de outliers.

Para ello, partimos de un modelo mixto completo y utilizamos el procedimiento dredge() para generar múltiples modelos candidatos con diferentes combinaciones de predictores. Esta búsqueda automática identifica los modelos con mejor equilibrio entre ajuste y complejidad, evaluado mediante el AICc. Para comparar modelos con distintos efectos fijos, es necesario ajustar el modelo inicial utilizando máxima verosimilitud (ML) en lugar de REML, que solo es apropiado cuando la estructura de efectos fijos permanece constante.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Cargar librerías necesarias
library(lme4)
library(MuMIn)

# Reajustamos el modelo de partida con método ML (obligatorio para comparar modelos)
modelo_mixto_ml <- lmer(
  happiness_score ~ support + life_exp + freedom + gdp + corruption + generosity + year + (1 | country) + (1 | year),
  data = df_sin_democracia_sin_na,
  REML = FALSE,
  na.action = na.fail
)

# Aplicar selección por AIC
modelo_optimo <- dredge(modelo_mixto_ml, trace = FALSE)

# Seleccionar el modelo con menor AIC
modelo_seleccionado <- get.models(modelo_optimo, 13)[[1]]
summary(modelo_seleccionado)

```

Incluir freedom, life_exp y support como efectos fijos en el modelo implica que se estima un coeficiente único y global para cada uno de estos predictores, es decir, se asume que su influencia sobre la felicidad es constante a lo largo de todos los países y años. Esto significa que, por ejemplo, un aumento en la libertad percibida tiene el mismo efecto esperado en el nivel de felicidad sin importar el país o el año en que se observe. Por otro lado, incorporar country y year como efectos aleatorios implica reconocer que existen variaciones estructurales en la felicidad entre países y entre años que no están completamente explicadas por los predictores fijos. Así, el modelo permite que cada país y cada año tenga su propio nivel base (intercepto), capturando influencias latentes como diferencias culturales, históricas o políticas entre países, y acontecimientos globales o coyunturales entre años, mejorando la capacidad del modelo para explicar y predecir la variabilidad observada en los datos.

Para evaluar la calidad del modelo, utilizaremos las siguientes medidas: el R² marginal, que representa la proporción de varianza explicada por los efectos fijos, y el R² condicional, que representa proporción de varianza explicada por todo el modelo (fijos + aleatorios).

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(performance)
r2(modelo_seleccionado)
```

Evaluando el modelo seleccionado, observamos que solo un 34.4% de la variabilidad del happiness_score es explicada por los efectos fijos (freedom, life_exp y support), lo que indica que estos predictores tienen un peso relevante pero no suficiente por sí solos para capturar toda la complejidad del fenómeno. Sin embargo, cuando se incorporan los efectos aleatorios de country y year, el porcentaje de varianza explicada asciende hasta el 89.5%, lo que revela que una parte sustancial de la variabilidad está asociada a diferencias sistemáticas entre países y entre años. Este resultado refuerza la idea de que la felicidad no solo depende de factores observables y cuantificables, sino también de contextos específicos, como elementos culturales, históricos o eventos coyunturales no recogidos en las variables del modelo. En definitiva, el modelo mixto con interceptos aleatorios por país y por año ofrece una representación mucho más realista de los datos, ya que reconoce explícitamente la estructura jerárquica y temporal del fenómeno analizado, captando variabilidad que un modelo clásico no podría explicar.

Como en cualquier modelo estadístico, es esencial verificar que las suposiciones sobre los residuos se cumplen también en el contexto de modelos mixtos. En particular, se evaluó la normalidad de los residuos, la homocedasticidad (varianza constante de los errores), y la ausencia de patrones sistemáticos entre residuos y valores ajustados. Para ello, se utilizan gráficos diagnósticos similares a los del modelo clásico, pero adaptados a la estructura jerárquica de los datos. 

```{r message=FALSE, warning=FALSE, echo=FALSE}
#| label: fig-modelo-top
#| echo: false
#| warning: false
#| fig-cap: "Gráficas para la validación del Modelo Lineal Mixto tras haber seleccionado el mejor modelo"
library(DHARMa)
library(sjPlot)
library(glmmTMB)
# Visualización rápida
plot_model(modelo_seleccionado, type = "diag")

# Diagnóstico más riguroso
sim_res <- simulateResiduals(fittedModel = modelo_seleccionado)
plot(sim_res)
testResiduals(sim_res)
```

### Normalidad

El gráfico QQ-plot de los residuos simulados muestra un ajuste bastante bueno a la diagonal teórica, con una alineación aceptable en la mayor parte de la distribución y solo ligeras desviaciones en las colas, lo que indica que los residuos del modelo se aproximan razonablemente a una distribución normal. Esta impresión visual se ve reforzada por la densidad empírica de los residuos, que es simétrica, centrada en cero y sin colas excesivamente pesadas. Además, el test de Kolmogorov-Smirnov aplicado a los residuos simulados a través de DHARMa proporciona un p-valor de 0.146, por lo que no se rechaza la hipótesis nula de normalidad. Esto indica que, estadísticamente, los residuos del modelo no presentan desviaciones significativas respecto a una distribución normal, cumpliendo así este supuesto teórico clave.

### Homocedasticidad

El gráfico de residuos frente a valores ajustados no muestra ninguna tendencia sistemática ni incremento evidente de la varianza a lo largo del rango de valores predichos, lo que sugiere que la varianza de los errores se mantiene aproximadamente constante. Esta impresión visual se confirma con el test de homogeneidad de la dispersión de DHARMa, que arroja un p-valor elevado (0.622), por lo que no se rechaza la hipótesis nula de homocedasticidad. En conjunto, se puede concluir que el modelo satisface también este segundo supuesto fundamental, lo cual refuerza su validez para inferencia y predicción.

### Outliers y estructura de los residuos

En lo que respecta a la presencia de observaciones atípicas, el test binomial exacto de DHARMa indica que la proporción de outliers observada no es significativamente mayor a la esperada por azar (p = 0.509). Esto sugiere que el número de observaciones extremas es bajo y no compromete la validez global del modelo. Además, el gráfico de residuos simulados frente a predichos muestra una nube de puntos sin patrones estructurados ni desviaciones sistemáticas en los cuantiles, lo que indica una buena especificación del modelo sin señales de estructura no capturada por los predictores incluidos.

### Conclusión del diagnóstico

Los resultados del diagnóstico indican que el modelo seleccionado cumple adecuadamente con los tres supuestos teóricos esenciales: normalidad de los residuos, homocedasticidad y baja proporción de outliers. A diferencia del modelo planteado inicialmente, que presentaba ciertas desviaciones respecto a estos supuestos, este modelo ajustado —con interceptos aleatorios por país y año— muestra un comportamiento más regular y apropiado para la inferencia estadística y la generación de predicciones. Por tanto, se considera un modelo robusto y válido para los objetivos analíticos del estudio.

### Interpretación de coeficientes

En la tabla de efectos fijos del modelo seleccionado, los coeficientes estimados (Estimate) indican el cambio esperado en la puntuación de felicidad (happiness_score) asociado a un incremento de una unidad en cada una de las variables independientes, manteniendo constantes las demás y considerando la estructura jerárquica del modelo (es decir, permitiendo que tanto el país como el año tengan interceptos aleatorios propios). Esto implica que los efectos aquí interpretados representan promedios poblacionales, corregidos por las variaciones específicas de cada país y de cada año.

- freedom (β = 1.1587): este coeficiente refleja una fuerte asociación entre la percepción de libertad y el bienestar subjetivo. La escala de freedom en este estudio va de 0 a 1, por lo que un incremento total en esta variable se traduciría, en promedio, en un aumento de 1.16 puntos en la puntuación de felicidad (que suele oscilar entre 3 y 8). Este efecto es sustantivamente muy relevante: sugiere que las sociedades donde las personas se sienten más libres para tomar decisiones sobre su vida tienden a ser considerablemente más felices. Esto refuerza la idea de que las políticas centradas en la autonomía individual y la participación ciudadana pueden tener un impacto directo y significativo en el bienestar general de una población.

- life_exp (β = 0.0208): aunque este coeficiente es numéricamente menor, hay que tener en cuenta que la variable de esperanza de vida saludable (life_exp) se mide en una escala mucho más amplia (por ejemplo, entre 45 y 75 años). Por tanto, un aumento de 10 años en la esperanza de vida se asocia con un incremento de aproximadamente 0.21 puntos en el índice de felicidad, lo cual no es despreciable. Este resultado indica que vivir más años con buena salud está positivamente relacionado con el bienestar subjetivo, y pone de relieve la importancia de la salud pública como determinante estructural de la felicidad.

- support (β = 1.2237): el coeficiente de apoyo social es el mayor del modelo, y también se refiere a una variable que va de 0 a 1. Esto implica que, a igualdad de condiciones, una mejora completa en la percepción de apoyo social puede aumentar en más de 1.22 puntos la puntuación de felicidad. Este resultado muestra que las relaciones interpersonales y el sentimiento de contar con alguien en momentos difíciles son uno de los pilares fundamentales del bienestar humano. De hecho, esta variable supera ligeramente a freedom tanto en magnitud del coeficiente como en significancia estadística (t = 12.34), consolidándose como el predictor más potente del modelo.

En conjunto, estos resultados muestran que las condiciones sociales y emocionales, como el apoyo mutuo y la percepción de libertad, junto con la calidad de vida física, medida a través de la esperanza de vida saludable, son los factores que más consistentemente explican las diferencias en felicidad entre países y a lo largo del tiempo. La fuerza y estabilidad de estos efectos, incluso al controlar por las diferencias estructurales entre países y años, sugiere que fomentar entornos sociales cohesionados, garantizar derechos individuales y mejorar la salud puede tener un impacto directo en el bienestar de la población.

### Predicción del Happiness Score para 2025

Usando el modelo mixto ajustado y extrapolando con los valores más recientes disponibles, se pueden obtener predicciones personalizadas por país. Esto permite construir un ranking proyectado de felicidad para 2025.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Cargar librerías necesarias
library(lme4)
library(dplyr)

# Crear una copia de la base de datos para 2025
datos_2025 <- df_sin_democracia_sin_na

# Sustituimos el valor del año por 2025 en todas las observaciones
datos_2025$year <- 2025

# Realizamos la predicción utilizando el modelo mixto
# allow.new.levels = TRUE permite predecir incluso si hay países nuevos o no observados
datos_2025$happiness_pred_2025 <- predict(modelo_seleccionado, newdata = datos_2025, allow.new.levels = TRUE)

# Agrupar por país y calcular la media de felicidad predicha en 2025 (si hay varias filas por país)
ranking_2025 <- datos_2025 %>%
  group_by(country) %>%
  summarise(happiness_pred_2025 = mean(happiness_pred_2025, na.rm = TRUE)) %>%
  arrange(desc(happiness_pred_2025)) %>%
  mutate(rank = row_number())

# Mostrar top 10
print(head(ranking_2025, 10))

# Mostrar bottom 10
print(tail(ranking_2025, 10))

ranking_2025 %>% 
  filter(country == "Spain")

ranking_2024 <- df_sin_democracia_sin_na %>%
  filter(year == 2024) %>%
  select(country, happiness_score) %>%
  arrange(desc(happiness_score)) %>%
  mutate(rank_2024 = row_number())

ranking_2024 %>%
  filter(country == "Spain")


```

Los países nórdicos continúan liderando el ranking global del Happiness Score estimado para 2025. Se observa que Finlandia encabeza el ranking con una predicción de 7.64 puntos, consolidando su posición como líder mundial en bienestar subjetivo. Le siguen Dinamarca (7.55), Islandia (7.50) y Noruega (7.43), todos muy cerca entre sí, lo que refleja una estabilidad en sus altos niveles de calidad de vida. El top 10 lo completan países con economías desarrolladas y estados de bienestar consolidados como Suiza, Países Bajos, Suecia, Nueva Zelanda, Israel y Australia, todos con puntuaciones superiores a 7.1.

En el extremo opuesto del ranking, los países con los niveles más bajos de felicidad prevista son Afganistán, que ocupa el último puesto (160º) con un valor de 2.88, seguido por República Centroafricana, Burundi y Sudán del Sur. Estas naciones presentan conflictos persistentes, pobreza extrema o inestabilidad política. Todas las puntuaciones están por debajo de 3.7, lo que refleja condiciones estructurales desfavorables que impactan fuertemente en el bienestar subjetivo.

Si nos fijamos en España, obtiene un Happiness Score previsto de 6.39, situándose en la posición 34 de 160. Esta puntuación refleja un nivel de felicidad moderadamente alto, por encima de la media global. Aunque no alcanza los niveles nórdicos, se encuentra en el tercio superior del ranking, lo que implica una posición destacada entre los países con mayor bienestar percibido. Aunque la puntuación de felicidad predicha para España en 2025 es ligeramente menor (6.39 vs. 6.42), la posición en el ranking mejora: sube del puesto 36 al 34. Esto implica que otros países han bajado más que España, permitiendo su ascenso en el ranking a pesar de una leve caída en su puntuación. Es un buen ejemplo de cómo el ranking depende no solo del valor absoluto, sino también del contexto comparativo entre países.

A partir de los resultados obtenidos en este capítulo, se ha desarrollado una aplicación interactiva en Shiny que permite explorar de forma dinámica los modelos mixtos ajustados sobre los datos de felicidad. La aplicación está diseñada para que el usuario pueda seleccionar distintas combinaciones de variables fijas, así como elegir entre distintos niveles de complejidad del modelo (intercepto aleatorio, pendiente aleatoria, etc.), y visualizar tanto los coeficientes estimados como las métricas de calidad del modelo (AIC, R² marginal y condicional). Además, permite generar predicciones personalizadas por país y año, lo que convierte a la app en una herramienta potente para observar cómo se comporta el modelo bajo distintos escenarios. Esta implementación traslada al entorno interactivo todo el proceso de modelado descrito en este capítulo, permitiendo al usuario comprobar en tiempo real cómo influyen los distintos predictores sobre la felicidad y cómo se ajustan los modelos a las características longitudinales y jerárquicas de los datos.


```{r include=FALSE, warning=FALSE}
## Regresión Lineal Múltiple
# Paquetes necesarios -----
library(ggplot2) 
library(ggfortify)
library(GGally)
library(lmtest)
library(tseries)
library(corrplot)
library(car)

# Planteamiento del modelo ----)
plot(df_original) # Hay muchas variables categóricas de las cuales nos desharemos
df_filtrado <- df_original %>%
  filter(year == 2024) %>%
  select(happiness_score, gdp, support, life_exp, 
         freedom, generosity, corruption)
plot(df_filtrado)
apply(df_filtrado, 2, shapiro.test) #el 2 es para aplicar por columnas
# Vemos como no hay normalidad en ninguna, pero como la muestra es grande podemos utilizar Pearson
round(cor(df_filtrado, method='pearson'),4) # redondeo a 4 decimales
# Me fijo en la primera columna porque quiero ver la relación de ventas con el resto de variables explicativas
# Parece ser que las variables que mejores predictoras serán de happines_score son social_support, gdp_per_capita y healthy_life_expectancy
cor.mtest(df_filtrado, method='pearson')
# Obtengo 3 matrices distintas: la primera tiene el p-valor asociado, la segunda el extremo inferior del intervalo de confianza y la tercera el extremo superior del intervalo de confianza
round(cor.mtest(df_filtrado, method='pearson')$p,4) # para ver el p-valor redondeado
ggpairs(df_filtrado)
ggpairs(df_filtrado, upper=list(continuous="cor", corMethod ="pearson"))
# Lo más probable es que generosity no sea un buen predictor de la felicidad

# Estimación de los parámetros ----
fit <- lm(happiness_score~gdp+support+life_exp+freedom+generosity+corruption, data=df_filtrado)
fit
# Hay algún parámetro parecido a 0; por lo que tenemos que ver si nos sobra algún parámetro.

# Comparación y selección de modelos ----
## Multicolinealidad
vif(fit)
# Como todos menores que 5, no hay problema de multicolinealidad y no vamos a quitar ninguna de las variables, aunque hay alguno que se acerca a 5

## Selección de variables explicativas
summary(fit)
### AIC y BIC
#### AIC
step(fit, k=2)
#### BIC
step(fit, k=log(nrow(df_filtrado)))
# Empiezo con el modelo saturado, va probando a sacar de una en una las variables. Nos interesa que el AIC sea lo más pequeño posible.
# El modelo final sería la felicidad en función del apoyo social, la esperanza de vida, el libre albedrío y la percepción de corrupción
fit <- lm(happiness_score~support+life_exp+freedom+corruption, data=df_filtrado)
fit.f <- step(fit, trace=0)
# Por defecto est? eligiendo el mejor modelo por AIC, aunque en este caso AIC y BIC devuelven el mismo modelo

# Adecuaci?n del modelo
summary(fit)
# El valor del estad?stico F (859.6) y el p-valor < alpha nos permiten concluir que podemos rechazar H0 y, por tanto, el modelo explica los datos. 
# Adem?s, el valor del R2 (0.8134) nos indica que el 81.34% de la varianza de la felicidad es explicada por las variables

# Diagn?stico del modelo
## An?lisis de los residuos
autoplot(fit)
# Parece que los valores de los residuos observados se alejan bastante de los residuos te?ricos

### Normalidad ==> NO SE CUMPLE
jarque.bera.test(fit$residuals)
# Los residuos no siguen una distribuci?n normal, por lo que la normalidad no se cumple

### Media cero ==> SE CUMPLE
mean(fit$residuals)
# Mirando la primera gr?fica, podemos ver como la gr?fica se parece un poco al eje de abscisas, aunque no haya un comportamiento perfectamente lineal de los datos; por lo que diría que la media cero  se cumple

### Homocedasticidad ==> NO SE CUMPLE
# No se mantiene muy constante, por lo que no parece que haya homocedasticidad
bptest(fit, studentize = FALSE)
# Viendo el p-valor, rechazamos H0, por lo que no tenemos varianza constante

### No correlaci?n ==> SE CUMPLE
# Parece ser que no siguen una fluctuaci?n aleatoria del todo
dwtest(fit, alternative='two.sided')
# Como el p-valor > alpha, no rechazamos H0, por lo que los residuos no est?n autocorrelacionados
# Por todo esto, el modelo no es fiable.
# Al principio, podemos observar que hay bastantes variables que pueden ser buenas predictoras del happiness_score. No obstante, en la selección de variables explicativas, vemos que el mejor modelo es aquel que cuenta con la percepción de la corrupción, la esperanza de vida, la libertad de tomar decisiones y el apoyo social. Al hacer el diagnóstico del modelo, vemos que el modelo no es fiable ya que los errores no tienen homocedasticidad ni normalidad.
```



